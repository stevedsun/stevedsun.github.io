<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloud Native Computing on Steve Sun</title><link>https://sund.site/categories/cloud-native-computing/</link><description>Recent content in Cloud Native Computing on Steve Sun</description><generator>Hugo -- gohugo.io</generator><language>En</language><lastBuildDate>Mon, 15 Apr 2024 16:44:40 +0800</lastBuildDate><atom:link href="https://sund.site/categories/cloud-native-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>审计追踪的设计</title><link>https://sund.site/posts/2024/audit-system-design/</link><pubDate>Mon, 15 Apr 2024 16:44:40 +0800</pubDate><guid>https://sund.site/posts/2024/audit-system-design/</guid><description>&lt;h2 id="什么是审计追踪audit-trail服务">什么是审计追踪（Audit Trail）服务？&lt;/h2>
&lt;blockquote>
&lt;p>审计轨迹（Audit trail、Audit log），也译作审计追踪、审计跟踪、审计日志、文件日志或轨迹纪录等名称，是一种作为信息系统审计手段的与安全相关的时间顺序记录、记录集和/或目的地和记录来源，它们提供了在任何时候影响特定操作，程序的活动顺序的文件证据或事件。 审计记录通常来自一些活动，例如：金融交易、科学研究和医疗保健数据交易，或个人、系统、账号以及其他实体的通信等活动。 透过对系统上的活动作时间顺序的纪录，从而监察系统是否存在违规的活动，协助审核人员快速的找出相关的交易资料。 ——维基百科&lt;/p>
&lt;/blockquote>
&lt;h2 id="审计追踪服务应该具备哪些能力">审计追踪服务应该具备哪些能力？&lt;/h2>
&lt;ol>
&lt;li>日志内容不可篡改。&lt;/li>
&lt;li>日志链结构完整：不可任意添加或删除单独的日志条目。&lt;/li>
&lt;li>兼容性：发送日志的客户端应该避免侵入式设计。&lt;/li>
&lt;li>系统的加密服务应该尽早初始化，以减少未受保护的日志。&lt;/li>
&lt;li>服务重启/关闭不应导致审核日志不一致。如果服务因紧急情况而关闭，审计日志应该是可验证的。&lt;/li>
&lt;li>密钥安全性：加密密钥（用于计算完整性检查）应存储在专用密钥存储中，并在内存中驻留最短的时间。&lt;/li>
&lt;li>性能：能够在几秒钟内验证受保护日志。&lt;/li>
&lt;li>日志轮换友好性：审核日志应与分布式系统典型的日志轮换策略兼容。&lt;/li>
&lt;li>可观测性：日志易于被解析（machine-readable）、人类可读（human-readable）。兼容主流日志处理程序的格式，维度设计便于日后做过滤筛选。&lt;/li>
&lt;/ol>
&lt;h2 id="审计追踪涉及的行业标准">审计追踪涉及的行业标准&lt;/h2>
&lt;p>常见的工业标准有 IEC62443、NIST SP 800-92。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>工业标准&lt;/th>
&lt;th>章节&lt;/th>
&lt;th>安全级别&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR2.8&lt;/td>
&lt;td>SL-C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR6.1&lt;/td>
&lt;td>SL-C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR6.2&lt;/td>
&lt;td>SL_C 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR1.13&lt;/td>
&lt;td>SL_C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR2.9&lt;/td>
&lt;td>SL_C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR2.10&lt;/td>
&lt;td>SL_C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR3.7&lt;/td>
&lt;td>SL_C 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IEC 62443-4-2:2019&lt;/td>
&lt;td>CR3.9&lt;/td>
&lt;td>SL_C 2&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="常见问题及应对措施">常见问题及应对措施&lt;/h2>
&lt;h3 id="日志格式协议">日志格式（协议）&lt;/h3>
&lt;p>对于本地运行的软件，通常 Syslog 具有更好的系统兼容性。对于使用 ELK 采集日志的项目更适合用 CEF，其他情况建议使用 自定义的 JSON。&lt;/p>
&lt;p>下面是三种格式（协议）的对比。&lt;/p>
&lt;h4 id="common-event-format-cefhttpsdocselasticcoenintegrationscef">&lt;a href="https://docs.elastic.co/en/integrations/cef">Common Event Format (CEF)&lt;/a>&lt;/h4>
&lt;p>Elastic-Search 使用的、一种基于 Event-souring 思想设计的日志格式。优点是冗余信息少，适合配合 ELK 体系构建监控系统。&lt;/p>
&lt;h4 id="sysloghttpsdatatrackerietforgdochtmlrfc5424">&lt;a href="https://datatracker.ietf.org/doc/html/rfc5424">Syslog&lt;/a>&lt;/h4>
&lt;p>Syslog 是 Linux 操作系统默认的审计日志格式，通常采用其 RFC5424 版本。大部分 SIEM&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> 系统都支持这种格式的导入。
Syslog 协议适配性很好，基于 mTLS 的 Syslog 传输可以在兼容传统软件的同时，最大程度保证系统的安全性。但是对于微服务来说，实现和维护标准协议成本较高。所以如 AWS CloudTrail, OpenTelemetry 等都选择更简单的 HTTPS + JSON 格式。&lt;/p>
&lt;h4 id="json">JSON&lt;/h4>
&lt;p>大部分 SaaS 产品都是用 JSON，简单高效。例如，下面是&lt;a href="https://opentelemetry.io/docs/specs/otel/logs/data-model/">OpenTelemetry 官方文档&lt;/a>提到的日志模型中的字段：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Timestamp&lt;/td>
&lt;td>Time when the event occurred.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ObservedTimestamp&lt;/td>
&lt;td>Time when the event was observed.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TraceId&lt;/td>
&lt;td>Request trace id.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SpanId&lt;/td>
&lt;td>Request span id.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TraceFlags&lt;/td>
&lt;td>W3C trace flag.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SeverityText&lt;/td>
&lt;td>The severity text (also known as log level).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SeverityNumber&lt;/td>
&lt;td>Numerical value of the severity.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Body&lt;/td>
&lt;td>The body of the log record.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resource&lt;/td>
&lt;td>Describes the source of the log.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>InstrumentationScope&lt;/td>
&lt;td>Describes the scope that emitted the log.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Attributes&lt;/td>
&lt;td>Additional information about the event.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="审计追踪的安全性要求">审计追踪的安全性要求&lt;/h3>
&lt;p>对于审计日志来说，安全性要求会被一般日志系统更高。&lt;/p>
&lt;p>安全性，通常可以从机密性（Confidentiality），完整性（Integrity），可用性（Availability）三个维度来考量。&lt;/p>
&lt;h4 id="机密性">机密性&lt;/h4>
&lt;p>攻击者可以通过系统的安全漏洞，获取特殊权限，进而查看某些审计日志。&lt;/p>
&lt;p>可以采取以下措施：&lt;/p>
&lt;ul>
&lt;li>加密日志：使用加密技术对日志进行保护，确保只有授权用户能够访问和修改日志。&lt;/li>
&lt;li>访问控制：限制对发送、接收日志接口的访问权限。&lt;/li>
&lt;li>敏感信息过滤：不应该在日志中记录用户敏感信息，如密码、证书等。&lt;/li>
&lt;/ul>
&lt;h4 id="完整性">完整性&lt;/h4>
&lt;p>攻击者可以通过系统的安全漏洞，修改、删除某些审计日志。&lt;/p>
&lt;p>除了上面提到的加密和权限控制，还可以采取以下措施：&lt;/p>
&lt;ul>
&lt;li>完整性检查&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>：在日志条目中添加哈希值，以便在验证日志时能够快速检测到任何篡改或截断。&lt;/li>
&lt;li>定期备份：定期备份日志，以防止攻击者删除或修改所有的日志条目。&lt;/li>
&lt;/ul>
&lt;h4 id="可用性">可用性&lt;/h4>
&lt;p>攻击者可以攻击审计追踪服务，导致审计追踪服务内存、磁盘空间不足等。&lt;/p>
&lt;ul>
&lt;li>设置最大用量限制：对内存、磁盘等服务器资源做出限制。&lt;/li>
&lt;li>监测和响应：及时监测系统资源指标和日志的变化，并对异常活动进行响应。&lt;/li>
&lt;/ul>
&lt;h2 id="开源项目的架构设计">开源项目的架构设计&lt;/h2>
&lt;p>根据自身项目需求，可以参考一些开源的架构设计。由于每个框架（方案）的设计侧重点不同，需要认真评估它们的优势和不足。&lt;/p>
&lt;h3 id="auditd">Auditd&lt;/h3>
&lt;p>大部分 Linux 系统默认的审计服务，配合 rsyslog 等工具，可以解决本地设备的日志采集、查看、过滤。&lt;/p>
&lt;ul>
&lt;li>优点：基于进程通信，标准日志格式，易于导出。性能优异。&lt;/li>
&lt;li>不足：标准繁琐，进程模型不适用于网络服务。&lt;/li>
&lt;/ul>
&lt;h3 id="aws-cloud-trail">AWS Cloud Trail&lt;/h3>
&lt;p>&lt;img src="https://sund.site/images/audit-system-design/aws-audit.png" alt="aws log">&lt;/p>
&lt;p>AWS 的 Cloud Trail 采用应用服务主动推送审计事件的模式，用户可以为设计追踪服务设置策略，收集到的日志会分别按需流入后续的批处理和流处理工具链中。&lt;/p>
&lt;ul>
&lt;li>优点：微服务设计，JSON 格式日志更灵活，中心化的日志收集服务易于集成更多应用服务和导出到开源数据处理工具。&lt;/li>
&lt;li>不足：分布式架构对存储、服务端加密、通信安全性和完整性要求更难实现。&lt;/li>
&lt;/ul>
&lt;h3 id="kubenetes">Kubenetes&lt;/h3>
&lt;p>&lt;img src="https://sund.site/images/audit-system-design/k8s-audit.png" alt="k8s log">&lt;/p>
&lt;p>K8s 的日志收集与 AWS 实现类似，也是基于中心化的服务，但是这套架构设计并非只为审计日志一种情况设计。&lt;/p>
&lt;ul>
&lt;li>优缺点同上&lt;/li>
&lt;/ul>
&lt;h3 id="opentelemetry">OpenTelemetry&lt;/h3>
&lt;p>&lt;img src="https://sund.site/images/audit-system-design/opentel.png" alt="OpenTel">&lt;/p>
&lt;p>OpenTelemetry 是现在云原生最主流的日志框架。可以支持侵入式（SDK）、非侵入式（Agent）两种日志采集模式。Collector 的设计可以让一部分日志处理的工作放在日志发送端完成。&lt;/p>
&lt;ul>
&lt;li>优点：微服务设计，支持 K8s 等基础设施，多语言多平台提供了 SDK 和扩展能力。有完善的安全、完整性考虑。未来可期。&lt;/li>
&lt;li>不足：大部分情况下日志采集依然需要侵入到 App 内部修改代码。日志收集工具对 Go 等语言支持不够好（截至本文写作时还是测试版）。&lt;/li>
&lt;/ul>
&lt;h2 id="小结由-claude-ai-提供">小结（由 Claude AI 提供）&lt;/h2>
&lt;p>审计追踪（Audit Trail）是指系统记录下所有影响操作或事件的时间顺序记录,用于追踪系统活动，核查是否存在违规行为。&lt;/p>
&lt;p>审计日志应具备以下特性:&lt;/p>
&lt;ul>
&lt;li>不可篡改(加密存储、完整性校验)&lt;/li>
&lt;li>高性能(快速验证)&lt;/li>
&lt;li>可观测性(机器/人类可读)&lt;/li>
&lt;li>安全性(保密性、可用性、完整性)&lt;/li>
&lt;/ul>
&lt;p>常见的审计日志格式有 Syslog、CEF、JSON 等,主要区别在于冗余信息、可读性和与日志收集系统的兼容性。&lt;/p>
&lt;p>审计日志具有较高的安全性要求：&lt;/p>
&lt;ul>
&lt;li>机密性：只有授权用户可访问,通过访问控制实现&lt;/li>
&lt;li>可用性：防止被攻击者删除或破坏,通过限制资源使用、多副本存储等实现&lt;/li>
&lt;li>完整性：防止被篡改或截断,通过加密、完整性校验等实现&lt;/li>
&lt;/ul>
&lt;p>一些典型的审计日志系统架构：&lt;/p>
&lt;ul>
&lt;li>Auditd(Linux 默认) + rsyslog 等工具，基于进程通信&lt;/li>
&lt;li>AWS CloudTrail 等云产品方案&lt;/li>
&lt;li>Kubernetes 架构&lt;/li>
&lt;li>OpenTelemetry 开源框架&lt;/li>
&lt;/ul>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>SIEM 是安全信息和事件管理(Security Information and Event Management)的缩写。&lt;a href="https://www.microsoft.com/en-us/security/business/security-101/what-is-siem">https://www.microsoft.com/en-us/security/business/security-101/what-is-siem&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>对于日志的加密，一般在服务端会对日志额外添加 checksum 链来校验。可以参考亚马逊的实现 &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html">server-side encryption (SSE-S3)&lt;/a>.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Kong网关极简入门</title><link>https://sund.site/posts/2023/kong-gateway/</link><pubDate>Fri, 23 Jun 2023 10:36:36 +0800</pubDate><guid>https://sund.site/posts/2023/kong-gateway/</guid><description>&lt;h2 id="基本概念">基本概念&lt;/h2>
&lt;blockquote>
&lt;p>Kong Gateway is a Lua application running in Nginx. Kong Gateway is distributed along with OpenResty, which is a bundle of modules that extend the lua-nginx-module.&lt;/p>
&lt;/blockquote>
&lt;p>Kong 是一个基于 Nginx 上运行的 Lua 程序。它改善了 Nginx 基于静态配置的缺点，可以动态添加插件和热部署。&lt;/p>
&lt;p>&lt;img src="https://sund.site/images/kong-gateway/Kong.png" alt="">&lt;/p>
&lt;h2 id="kong-的基础模块">Kong 的基础模块&lt;/h2>
&lt;p>&lt;strong>Service&lt;/strong>是后端服务的抽象。&lt;/p>
&lt;p>&lt;strong>Routes&lt;/strong>是 client 到后端服务的路由规则的抽象。如，为不同的 client 设置不同的认证规则。&lt;/p>
&lt;p>Kong 的 routes 有两种模式 &lt;code>traditional_compat&lt;/code> 和 &lt;code>expressions&lt;/code> 。&lt;/p>
&lt;ul>
&lt;li>&lt;code>traditional_compat&lt;/code> ：旧的基于通配符等匹配优先级的模式。&lt;/li>
&lt;li>&lt;code>expressions&lt;/code> ：新的基于表达式的匹配模式。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Upstreams&lt;/strong>是一个运维对象，在 Services 和真正的后台 API 服务之间，用来负载均衡。&lt;/p>
&lt;p>&lt;strong>Plugins&lt;/strong>是用 lua 或 go 编写的插件，分为 Kong 官方提供的插件和第三方插件。&lt;/p>
&lt;h2 id="kong-的工作原理">Kong 的工作原理&lt;/h2>
&lt;p>Kong 支持三类协议：HTTP/HTTPS，TCL/TLS 和 GRPC/GRPCS。每种协议由不同的参数组成：&lt;/p>
&lt;ul>
&lt;li>&lt;code>http&lt;/code>: &lt;code>methods&lt;/code>, &lt;code>hosts&lt;/code>, &lt;code>headers&lt;/code>, &lt;code>paths&lt;/code> (and &lt;code>snis&lt;/code>, if &lt;code>https&lt;/code>)&lt;/li>
&lt;li>&lt;code>tcp&lt;/code>: &lt;code>sources&lt;/code>, &lt;code>destinations&lt;/code> (and &lt;code>snis&lt;/code>, if &lt;code>tls&lt;/code>)&lt;/li>
&lt;li>&lt;code>grpc&lt;/code>: &lt;code>hosts&lt;/code>, &lt;code>headers&lt;/code>, &lt;code>paths&lt;/code> (and &lt;code>snis&lt;/code>, if &lt;code>grpcs&lt;/code>)&lt;/li>
&lt;/ul>
&lt;p>Kong 支持按 HTTP header、URL、method、源地址、目标地址、&lt;a href="https://en.wikipedia.org/wiki/Server_Name_Indication">Server Name Indication&lt;/a> 来路由请求。&lt;/p>
&lt;p>Kong 默认以&lt;a href="https://tools.ietf.org/html/rfc3986">RFC 3986&lt;/a>协议对请求的路径处理。&lt;/p>
&lt;h3 id="kong-匹配规则的优先级">Kong 匹配规则的优先级&lt;/h3>
&lt;p>按最多匹配的规则来路由。&lt;/p>
&lt;blockquote>
&lt;p>The rule is: &lt;strong>when evaluating a request, Kong Gateway first tries to match the
routes with the most rules&lt;/strong>.&lt;/p>
&lt;/blockquote>
&lt;p>当所有匹配规则检查完，Kong 会通过下层的 Nginx 模块发送请求。Response 返回之后，Kong 再经过&lt;code>header_filter&lt;/code>和&lt;code>body_filter&lt;/code>两个 hook 来修改 response header 和 body。&lt;/p>
&lt;h3 id="对-websocket-的支持">对 WebSocket 的支持&lt;/h3>
&lt;p>有两种配置方式来路由 wss 请求：&lt;/p>
&lt;ul>
&lt;li>HTTP(S) services and routes：把 wss 流量当作不透明的字节流。&lt;/li>
&lt;li>WS(S) services and routes (&lt;strong>企业版功能&lt;/strong>)：可以更好的用 websocket 插件控制流量。&lt;/li>
&lt;/ul>
&lt;h3 id="负载均衡">负载均衡&lt;/h3>
&lt;p>Kong 支持两类负载均衡方式&lt;/p>
&lt;ul>
&lt;li>基于 DNS （服务注册和发现是静态的）&lt;/li>
&lt;li>基于哈希环的动态负载均衡（服务注册发现由 Kong 管理，可以动态增删）&lt;/li>
&lt;/ul>
&lt;p>这部分跟 Nginx 类似。&lt;/p>
&lt;h3 id="健康检查">健康检查&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>active checks&lt;/strong>（心跳检查）&lt;/li>
&lt;li>&lt;strong>passive checks&lt;/strong>（被动检查，即断路器，根据流量检查）&lt;/li>
&lt;/ul></description></item><item><title>分布式缓存系统的设计</title><link>https://sund.site/posts/2021/distributed-cache/</link><pubDate>Thu, 18 Mar 2021 15:32:57 +0800</pubDate><guid>https://sund.site/posts/2021/distributed-cache/</guid><description>&lt;p>很久不写技术文章了。这是一篇关于 Redis 构建分布式缓存系统的总结，结合之前项目上的使用场景，做一个系统性的梳理。&lt;/p>
&lt;p>下面就以我做过的商品预约平台项目作为引子，引出分布式缓存设计的一些要点。&lt;/p>
&lt;p>该商品预约平台的背景如下：&lt;/p>
&lt;ul>
&lt;li>该系统由多个微服务组成&lt;/li>
&lt;li>预约的过程：用户可以选择指定门店，指定日期到店提领商品，如果对应门店和日期没有库存，则不能预约&lt;/li>
&lt;li>因为“预约”的是未来时刻的库存，所以门店的未来某个时间剩余库存是通过一系列公式计算得出的。这个公式比较复杂，考虑到了用户指定的日期是否在配货周期内等因素，这里省略掉细节&lt;/li>
&lt;li>每年节日高峰时期，用户会集中预约商品，导致服务压力骤增。又因为未来日期的库存需要动态计算的特点（比如 A 预约了 1 月 1 日的最后一件商品，B 就会无法在该日预约），不同用户的预约操作会互相影响，严重时导致数据库死锁、数据不一致等问题&lt;/li>
&lt;/ul>
&lt;p>基于以上背景，这个预约系统的设计必须将性能作为主要优化目标，而缓存作为性能优化的不二选择，就承担了重要职责。&lt;/p>
&lt;h2 id="识别热点数据">识别热点数据&lt;/h2>
&lt;p>并不是所有数据都有必要被缓存，往往缓存的数据具有以下几个特点：&lt;/p>
&lt;ul>
&lt;li>读写比很高。如果写操作比读操作还多，缓存系统频繁更新会大大降低可用性&lt;/li>
&lt;li>是热点数据。因为内存的价格昂贵，所以按照 2-8 原则，20%热点数据才值得被缓存&lt;/li>
&lt;li>能够容忍短时间的不一致&lt;/li>
&lt;/ul>
&lt;p>结合项目需要，排除掉一些不适合缓存的数据：&lt;/p>
&lt;ul>
&lt;li>对于那些只读的、配置相关的数据，只需要做进程缓存（使用 Guava Cache），在服务启动时加载数据到内存就可以了&lt;/li>
&lt;li>尽量用 CDN 和 Nginx 静态缓存来解决大部分不常更新的资源&lt;/li>
&lt;/ul>
&lt;p>对于该预约项目，用户最频繁查询的数据是不同门店在不同日期下的库存数量。这类数据是缓存设计的重点照顾对象：&lt;/p>
&lt;ul>
&lt;li>用户选择了指定城市、指定门店后，系统会返回最近 30 天的库存信息，用户只可能修改其中一条信息。所以读写比很高&lt;/li>
&lt;li>库存信息是预约订单流程的必备步骤，而且是跨服务调用（预约服务 -&amp;gt; 库存服务）的数据，所以涉及到大量网络请求、数据库查询。&lt;/li>
&lt;/ul>
&lt;h2 id="指定性能优化的指标">指定性能优化的指标&lt;/h2>
&lt;p>在即将完成业务系统开发时，我们就根据 &lt;a href="https://sre.google/books/">Google SRE Books&lt;/a> 提到的四个黄金指标，制定了监控系统性能的四个维度：&lt;/p>
&lt;ul>
&lt;li>请求率&lt;/li>
&lt;li>错误数，非 200 返回结果数量&lt;/li>
&lt;li>响应时间&lt;/li>
&lt;li>资源利用率（CPU、内存）&lt;/li>
&lt;/ul>
&lt;p>我们使用 Prometheus + Grafana 的组合实现监控可视化，这样每次测试人员进行压力测试时，都可以通过这些指标对系统进行调整。缓存影响最大的指标是&lt;strong>请求率&lt;/strong>（一般用 TPS 或者 QPS）和&lt;strong>响应时间&lt;/strong>。所以在设计缓存系统时，要不断参照这两个指标进行优化。&lt;/p>
&lt;h2 id="缓存的设计的实践">缓存的设计的实践&lt;/h2>
&lt;h3 id="分级缓存">分级缓存&lt;/h3>
&lt;p>为了不让某一接口或者微服务的缓存失效导致其他接口或服务的并发量暴增，就要针对不同来源（数据库的表、接口等）的数据做分级缓存。比如用户在一次查询中涉及到“附近可预约门店”的查询、“活动期间不同日期剩余库存”的查询、“已预约数量“的查询，这三种查询逐层依赖后边的查询结果。&lt;/p>
&lt;p>假设如果只针对库存数量做缓存，一旦这部分缓存失效，那么“附近可预约门店”的查询就会直接访问数据库查询全部门店的剩余库存来确定哪个门店可以预约。这样就导致查询库存的接口并发量骤增。所以&lt;strong>分级缓存一定程度上缓解了缓存雪崩的问题&lt;/strong>。&lt;/p>
&lt;h3 id="自动化测试-api-参数合法性">自动化测试 API 参数合法性&lt;/h3>
&lt;p>我们的 QA 通常会写自动化脚本对后端 API 做定期的扫描，检查哪些接口的数据输入、输出有不合法的类型或是数值范围。除了巩固系统的健壮性，还能帮助缓存系统抵御&lt;strong>缓存穿透&lt;/strong>的风险。&lt;/p>
&lt;h3 id="缓存和数据库双写问题">缓存和数据库双写问题&lt;/h3>
&lt;p>这是一个“先淘汰缓存&amp;quot;还是”先写数据库“的问题。通常没有明确的最佳方法。我们采用 &lt;a href="https://dzone.com/articles/cache-aside-pattern">&lt;strong>Cache-Aside Pattern&lt;/strong>&lt;/a> 的方式：&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>&lt;strong>失效&lt;/strong>：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。&lt;/li>
&lt;li>&lt;strong>命中&lt;/strong>：应用程序从 cache 中取数据，取到后返回。&lt;/li>
&lt;li>&lt;strong>更新&lt;/strong>：先把数据存到数据库中，成功后，再让缓存失效。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>缺点：可能有小概率脏数据&lt;/strong>。比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。&lt;/p>
&lt;/blockquote>
&lt;p>考虑到写操作通常比读操作时间更长，所以 Cache-Aside Pattern 中的脏数据概率非常小，即便发生，用户在实际下单时系统仍然会去数据库里做数据校验，不会影响业务数据的正确性。&lt;/p>
&lt;p>如果对缓存一致性有更高要求，可以采用&lt;a href="https://juejin.cn/post/6844903805641818120">延时双删策略或异步更新缓存&lt;/a>。不过这两种方式本质都是用一定程度的串行化操作来解决并发造成的问题。&lt;/p>
&lt;h3 id="预热">预热&lt;/h3>
&lt;p>预加载热点数据时需要注意的点是，要考虑好服务一旦重启或是生产环境发生事故，要避免服务重启后再次造成二次事故。&lt;/p>
&lt;h2 id="缓存系统常见的问题和应对思路">缓存系统常见的问题和应对思路&lt;/h2>
&lt;p>首先要保证应用服务能做好熔断、限流、降级的措施。然后再针对不同情况做应对处理。&lt;/p>
&lt;h3 id="缓存雪崩">缓存雪崩&lt;/h3>
&lt;p>原因：热点缓存数据批量过期，导致大量缓存失效。&lt;/p>
&lt;p>解决思路：&lt;/p>
&lt;ul>
&lt;li>错开过期时间、随机过期时间&lt;/li>
&lt;li>构建多级缓存&lt;/li>
&lt;li>避免热点数据频繁淘汰（如修改 Redis 淘汰策略为 LRU）&lt;/li>
&lt;li>必要时限流、降级&lt;/li>
&lt;/ul>
&lt;h3 id="缓存击穿">缓存击穿&lt;/h3>
&lt;p>原因：热点 Key 突然过期。&lt;/p>
&lt;p>解决思路：&lt;/p>
&lt;ul>
&lt;li>设计系统时针对性预防措施，比如热点 Key 的更新策略不依据时间，而是程序控制&lt;/li>
&lt;li>配合监控和后台调整，保证高峰时段热点 key 可用&lt;/li>
&lt;li>必要时限流、降级&lt;/li>
&lt;/ul>
&lt;h3 id="缓存穿透">缓存穿透&lt;/h3>
&lt;p>原因：黑客通过访问缓存中不存在的数据，将大量请求直达数据库。&lt;/p>
&lt;p>解决思路：&lt;/p>
&lt;ul>
&lt;li>监控报警&lt;/li>
&lt;li>在服务层做好熔断&lt;/li>
&lt;/ul>
&lt;h2 id="小结">小结&lt;/h2>
&lt;p>在设计缓存系统时优先排除掉大部分不需要缓存或者通过进程本地缓存的数据。搭建合理的监控手段，自动化测试框架，再结合预热、缓存淘汰策略、双写策略等最佳实践方法，不断优化缓存性能。&lt;/p>
&lt;p>尤其要注意缓存的集中常见问题：雪崩、击穿和穿透。做好应用服务的熔断、降级、限流措施，保证在事故发生时针对每种情况都有预案。&lt;/p></description></item></channel></rss>