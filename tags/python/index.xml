<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>python on 电波障害</title><link>https://sund.site/tags/python/</link><description>Recent content in python on 电波障害</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Fri, 14 Jul 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://sund.site/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>《Python源码剖析》第三部分——Python虚拟机进阶</title><link>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86python%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9B%E9%98%B6/</link><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86python%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9B%E9%98%B6/</guid><description>Python 环境初始化 进程启动后创建PyInterpreterObject，PyInterpreterObject里面维护了全局module映射表interp-&amp;gt;modules，该表默认初始化为__buildin__模块，
Python 的 import 机制 Python虚拟机在执行“import A”时，会为package A创建一个module对象，同时会在该module维护的dict中添加两个表示元信息的属性：name__和__path。而Python虚拟机从A/init.py中执行“import mod1”时，也会为mod1创建一个module对象，同时也会设置__name__属性，但是这时就不设置__path__属性了。
package是由module聚合而成。更清楚的表述是：module属于一个package。我们不能说，module1属于module2。我们前面已经看到，module的路径实际上是一种树状结构，从图14-11中可以看到，在这个树状结构中，module的父节点只能是package，而不可能是另一个module。
GIL Python虚拟机使用一个全局解释器锁（Global Interpreter Lock，GIL）来互斥线程对python虚拟机的使用。
注意这里GIL是解释器一级的互斥锁，也就是同一时间只能有一个线程占用python解释器。所以GIL是用来让操作系统中分配的多个线程互斥的使用python解释器的，是建立在系统线程调度基础之上的一套C API互斥机制，是比操作系统线程资源更大粒度的锁。
Python的线程是基于操作系统原生线程的，所以python的线程不是「虚拟出来的」。
那么究竟Python会在众多的等待线程中选择哪一个幸运儿呢？答案是，不知道。没错，对于这个问题，Python完全没有插手，而是交给了底层的操作系统来解决。也就是说，Python借用了底层操作系统所提供的线程调度机制来决定下一个进入Python解释器的线程究竟是谁。
GIL在C里对应的结构：
[thread_nt.h] typedef struct NRMUTEX { LONG owned ; DWORD thread_id ; HANDLE hevent ; } NRMUTEX, *PNRMUTEX ; 其中owned初始化为-1，表示锁可用，否则为不可用。thread_id代表线程id，最后一个是平台相关的变量，win32上是一个event内核对象。
多线程 - 标准调度 当Python启动时，是并不支持多线程的。换句话说，Python中支持多线程的数据结构以及GIL都是没有创建的，Python之所以有这种行为是因为大多数的Python程序都不需要多线程的支持
书中指出，由于python的多线程标准调度机制是有代价的，所以默认单线程不初始化GIL。
主线程启动后，会用ident = PyThread_start_new_thread(t_bootstrap, (void*) boot);函数调用操作系统内核接口创建子线程，然后主线程挂起等待obj.done。注意，此时主线程中持有GIL。 主线程等待的这段时间里，子线程将自己的线程id等信息设置好，通知内核对象obj.done，唤醒等待中的主线程。此刻，主线程和子线程都同时由操作系统调度，但是主线程一直持有着GIL。 子线程继续执行后进入python解释器，发现需要等待获取GIL。此时子线程主动将自己挂起(而不是由操作系统挂起)。这样就进入了两个线程通过GIL调度的阶段。 主线程被唤醒后，继续执行，直到python内置的时钟计时器_Py_Ticker结束才将自己挂起，让出GIL(_Py_Ticker会在每次执行一条字节码后自动减1，初始默认为100)。 通过上面4步，python的两个线程就完成了从系统调度上升到python标准GIL调度的流程。
阻塞调度 如同上面流程介绍的，标准调度是python使用软件时钟调度线程，那么有时候python的线程会自我阻塞，比如raw_input()、sleep()等函数，这时python就会使用阻塞调度的方式。
主线程调用sleep(1)后，调用Py_BEGIN_ALLOW_THREADS立刻释放GIL，然后调用操作系统的sleep操作。此时主线程就由操作系统自动管理。 子线程拿到GIL。此时主线程和子线程同时可被操作系统调度。操作系统在执行一段时间子线程后会挂起，调度主线程，发现主线程sleep没结束就挂起主线程，就继续唤醒子线程执行。 当主线程sleep结束，操作系统唤醒主线程。主线程调用Py_END_ALLOW_THREADS再次申请GIL，重新进入python标准调度流程。 可见python在保证线程安全的前提下，允许线程在某些时刻脱离GIL标准调度流程。</description></item><item><title>《Python源码剖析》第二部分——Python虚拟机基础</title><link>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86python%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E7%A1%80/</link><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86python%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E7%A1%80/</guid><description>Python执行环境 在编译过程中，这些包含在Python源代码中的静态信息都会被Python编译器收集起来，编译的结果中包含了字符串，常量值，字节码等在源代码中出现的一切有用的静态信息。在Python运行期间，这些源文件中提供的静态信息最终会被存储在一个运行时的对象中，当Python运行结束后，这个运行时对象中所包含的信息甚至还会被存储在一种文件中。这个对象和文件就是我们这章探索的重点：PyCodeObject对象和pyc文件。
在程序运行期间，编译结果存在于内存的PyCodeObject对象中；而Python结束运行后，编译结果又被保存到了pyc文件中。当下一次运行相同的程序时，Python会根据pyc文件中记录的编译结果直接建立内存中的PyCodeObject对象，而不用再次对源文件进行编译了。
从文章摘录可见，python生成的不是编译后的文件，而是.py文件对应的静态信息——PyCodeObject，这里包括了字节码指令序列、字符串、常量。每个名字空间(类、模块、函数)都对应一个独立的PyCodeObject。(python连编译后的文件里存的都是个对象！)
不被import的py文件不会生成pyc。标准库里有py_compile等方法也可以生成pyc。
import机制 导入某个模块时，先查找对应的pyc，如果没有pyc就生成然后import这个pyc。(所以实际导入的并不是py文件，而是py文件编译后的PyCodeObject)。
PyFrameObject Python程序运行时的「执行环境」。参考操作系统执行可执行文件的过程。Python也是将函数对应的执行环境封装成栈帧的形式加载进内存。
typedef struct _frame { PyObject_VAR_HEAD struct _frame *f_back; //执行环境链上的前一个frame PyCodeObject *f_code; //PyCodeObject对象 PyObject *f_builtins; //builtin名字空间 PyObject *f_globals; //global名字空间 PyObject *f_locals; //local名字空间 PyObject **f_valuestack; //运行时栈的栈底位置 PyObject **f_stacktop; //运行时栈的栈顶位置 …… int f_lasti; //上一条字节码指令在f_code中的偏移位置 int f_lineno; //当前字节码对应的源代码行 …… //动态内存，维护（局部变量+cell对象集合+free对象集合+运行时栈）所需要的空间 PyObject *f_localsplus[1]; } PyFrameObject; Python标准库的sys._getframe()可以动态的在程序执行时获取当前内存中活跃的PyFrameObject信息。
LEGB 规则 即python作用域的查找顺序是local-enclosing-global-buildin。看下面代码：
a = 1 def g(): print a def f(): print a //[1] a = 2 //[2] print a g() 代码在[1]处会抛出异常，原因是python在编译阶段就把静态数据(局部变量、全局变量、字节码)放入pyc里，执行到f()里时，查找到a是在local作用域里定义的而不是global里，但是此时local的a还没赋值，所以就会抛出异常。由此可见，python作用域信息是在静态编译时就处理好了的。</description></item><item><title>《Python源码剖析》第一部分——Python对象基础</title><link>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86python%E5%AF%B9%E8%B1%A1%E5%9F%BA%E7%A1%80/</link><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/2017/07/python%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86python%E5%AF%B9%E8%B1%A1%E5%9F%BA%E7%A1%80/</guid><description>Python的对象初始化 在Python中，对象就是为C中的结构体在堆上申请的一块内存，一般来说，对象是不能被静态初始化的，并且也不能在栈空间上生存。唯一的例外就是类型对象，Python中所有的内建的类型对象（如整数类型对象，字符串类型对象）都是被静态初始化的。
python 的对象不像 C 是分配在栈、堆、data segment等位置，而是全部分配在堆上！只有python内置类型在初始化时候才是被C语言层静态初始化。
PyObject内部就两样：引用计数器、类型对象指针。
类型对象的定义：
typedef struct _typeobject { PyObject_VAR_HEAD char *tp_name; /* For printing, in format &amp;#34;&amp;lt;module&amp;gt;.&amp;lt;name&amp;gt;&amp;#34; */ int tp_basicsize, tp_itemsize; /* For allocation */ /* Methods to implement standard operations */ destructor tp_dealloc; printfunc tp_print; …… /* More standard operations (here for binary compatibility) */ hashfunc tp_hash; ternaryfunc tp_call; …… } PyTypeObject; PyObject_VAR_HEAD是可变类型的头信息，其中除了PyObject_HEAD的内容外，额外添加了一个代表该对象元素数量的整型。从上边代码可见，python的类型也是一个可变对象。
Python的多态 Python中所有类型在初始化后，在C语言层面都使用同一种指针PyObject *，所以python实现多态就非常容易。任何函数的参数都是一个PyObject类型指针，也就不存在编译器需要判断函数参数类型。
Python对象内存池 Python为了避免频繁的释放对象，采用了内存池的机制，在对象引用计数为0时，不会释放内存，而是将内存交还给内存池供python重新分配使用。每一种python类型，都有特定的内存池机制。
整数对象 -5至257之间的小整数，存储在「小整数数组」里，这个数组Python自动创建，每次创建一个小整数，就指向这个数组里对应的PyIntObject值并把PyIntObject的计数加1。(因此在-5到257之间的数实际指向同一片内存空间，整数-5和-5的内存地址肯定是一样的)
大整数则由一个叫block_list的链表管理，每次分配一个大整数就在free_list(一个指向空闲内存block的指针)里拿出一个节点并把free_list后移一个block。关于free_list是如何把尚未分配的内存和已被释放的内存链接起来的，可以参见书中113页的插图理解。
值得注意的是，python用于分配给整型的堆内存是不会自行销毁的，而是不断复用。也就是说，同一时间如果同时使用的整型太多，会消耗大量内存，并且这些内存在python关闭之前一直被python持有着。</description></item><item><title>Python2 中字符类型的一些坑</title><link>https://sund.site/posts/2017/01/python2-%E4%B8%AD%E5%AD%97%E7%AC%A6%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</link><pubDate>Wed, 11 Jan 2017 11:09:00 +0000</pubDate><guid>https://sund.site/posts/2017/01/python2-%E4%B8%AD%E5%AD%97%E7%AC%A6%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</guid><description>问题 有一道面试题是这样的：
a = u&amp;#39;China&amp;#39; b = &amp;#39;China&amp;#39; c = u&amp;#39;中国&amp;#39; d = &amp;#39;中国&amp;#39; # 1 print &amp;#39;%s%s&amp;#39; % (a, b) # 2 print &amp;#39;%s&amp;#39; % c # 3 print &amp;#39;%s&amp;#39; % d # 4 print &amp;#39;%s%s&amp;#39; % (c, d) 判断打印后的效果。
先说正确答案，只有最后一行会报错。
分析 在Python2里，默认的字符类型是str，这个str和Python3的str完全不同，Python2的str类型是8位的ascii序列。Python2在处理str类型转换时遵循这样的规则：如果被处理的str型变量值小于7位，就可以和unicode类型混用。可以做+连接，格式化等操作，同unicode享受同样的待遇。
Python2在格式化字符时，会把str格式化为str，如果字符串里混入了unicode，就会把其他字符都转化为unicode。所以这道题里1处的a，b两个值混合后的字符就是一个unicode字符串，c和d单独格式化后仍保留了自己的格式。但是Python2在格式化代码位置4时，发现c是unicode而d不是，就会尝试按照上面的混用规则，格式化d为unicode类型，但是d的值'中国'显然是一个大于7位的str，因此Python2抛出UnicodeDecodeError。
在Python3里，str类型则变成了一个纯unicode字符，也就是说Python3里的str等价于Python2里的unicode类型。Python3里为了清晰明了，使用bytes代表8位ascii序列。除此之外，Python3严格禁止混用两种类型。
总结 使用Python2处理字符串，尤其是中文字符串，最好前边加上u Python2里不要混用str和unicode，如果处理文本时，先将全部数据格式化成unicode 能用Python3尽量不用Python2 (废话) 参考资料： 《Effective Python》 Brett Slatkin. 不愿意透露姓名的某厂面试官</description></item><item><title>Python yield关键字的底层实现</title><link>https://sund.site/posts/2016/12/python-yield%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Wed, 28 Dec 2016 18:00:00 +0000</pubDate><guid>https://sund.site/posts/2016/12/python-yield%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>这几天面试被问到类似的问题，顺便看了看Python的源码，参考网上的教程，总结一下yield关键字在C层面是如何实现的。
举个栗子 我们先看一个python生成器函数的例子：
from dis import dis def func(): i = 4 yield i print i dis(func) a =func() a.next() a.next() 使用python的库dis可以直接查看python虚拟机运行的字节码。dis(func)的打印如下：
6 0 LOAD_CONST 1 (4) 3 STORE_FAST 0 (i) 7 6 LOAD_FAST 0 (i) 9 YIELD_VALUE 10 POP_TOP 8 11 LOAD_FAST 0 (i) 14 PRINT_ITEM 15 PRINT_NEWLINE 16 LOAD_CONST 0 (None) 19 RETURN_VALUE 我们猜测其中第二列(代表字节码偏移量)为9的指令YIELD_VALUE就是yield关键字的执行代码，进入Python2.7.12源码目录，在解释器执行字节码的主函数PyEval_EvalFrameEx中找到了下面一段：
TARGET_NOARG(YIELD_VALUE) { retval = POP(); f-&amp;gt;f_stacktop = stack_pointer; why = WHY_YIELD; // 跳转到fast_yield处。fast_yield里处理了一下状态位然后返回结果 goto fast_yield; } 其中TARGET_NOARG为封装了case语句的宏，这句话的意思是，如果字节码是YIELD_VALUE，就把栈顶元素赋值给retval，然后跳转到fast_yield处，fast_yield处代码进行了一些状态判断后直接返回了retval。</description></item><item><title>Python 巧妙地将rpc接口封装成pythonic的链式调用</title><link>https://sund.site/posts/2016/10/python-%E5%B7%A7%E5%A6%99%E5%9C%B0%E5%B0%86rpc%E6%8E%A5%E5%8F%A3%E5%B0%81%E8%A3%85%E6%88%90pythonic%E7%9A%84%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8/</link><pubDate>Tue, 25 Oct 2016 15:40:43 +0000</pubDate><guid>https://sund.site/posts/2016/10/python-%E5%B7%A7%E5%A6%99%E5%9C%B0%E5%B0%86rpc%E6%8E%A5%E5%8F%A3%E5%B0%81%E8%A3%85%E6%88%90pythonic%E7%9A%84%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8/</guid><description>这是一个外国人实现的Zabbix(一个开源监控工具)的Python Client——pyzabbix里的代码片段。
RPC调用 Rpc调用的流程是向rpc服务端指定的uri(如http://www.abc.com/jsonrpc.php) 发送json(或其他双方约定格式)数据包，数据包里有rpc版本信息、方法名、参数等。下面Zabbix类里的do_request方法就完成了将方法名和方法参数打包json后发送请求的过程。
class Zabbix(object): # ... skip other class methods def do_request(self, method, params=None): request_json = { &amp;#39;jsonrpc&amp;#39;: &amp;#39;2.0&amp;#39;, &amp;#39;method&amp;#39;: method, &amp;#39;params&amp;#39;: params or {}, &amp;#39;id&amp;#39;: self.id, } response = self.session.post( self.url, data=json.dumps(request_json), timeout=self.timeout ) 技巧 但是为了方便，我们在python里一般使用zabbixclient.host.get(args)这样的链式调用，而不用zabbixclient('host.get', args)这样的调用方式。pyzabbix的作者巧妙的实现了这样的转换。
class Zabbix(object): # ... skip other class methods def do_request(self, method, params=None): request_json = { &amp;#39;jsonrpc&amp;#39;: &amp;#39;2.0&amp;#39;, &amp;#39;method&amp;#39;: method, &amp;#39;params&amp;#39;: params or {}, &amp;#39;id&amp;#39;: self.id, } response = self.session.post( self.</description></item><item><title>Python Fabric库无法启动后台进程的问题和解决办法</title><link>https://sund.site/posts/2016/10/python-fabric%E5%BA%93%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link><pubDate>Wed, 19 Oct 2016 16:25:51 +0000</pubDate><guid>https://sund.site/posts/2016/10/python-fabric%E5%BA%93%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid><description>问题和处理方法 Python 的 Fabric 库能够方便的远程操作Linux主机执行命令或传输文件。其实现方式就是底层实现ssh协议，例如执行下面代码的run方法，在目标主机上启动一个zabbix后台服务：
from fabric import api from fabric.tasks import Task class Zabbix(Task): def run(self, kwargs): with api.settings(host_string=&amp;#39;192.168.1.2&amp;#39;, user=&amp;#39;root&amp;#39;, password=&amp;#39;123456&amp;#39;): api.run(&amp;#39;service zabbix_agentd start&amp;#39;) 但是这样操作后虽然 Fabric 的 output 返回结果打印是启动成功，但是ssh登录目标主机，却不见 zabbix_agentd 进程，这说明没有真正启动起来。
我查询了 Fabric 文档，发现需要在api.run里添加参数pty=False。
api.run(&amp;#39;service zabbix_agentd start&amp;#39;， pty=False) 这样就成功启动了后台进程。
原因 什么是pty？ pty 是 pseudo-tty，众所周知 tty 是 Linux 支持输入与输出的终端设备，在 shell 下执行ps可以查看每个进程对应的tty设备号，如ttys0001。
pty 是为了解决远程连接时一方不希望对方直接ssh连接到主机上而诞生的「虚拟设备」，即伪tty，其原理是在远程主机和本地之间同时启动pty端口连接终端，可以类比进程间的通道，pty两端同时执行输入输出操作，如同本地直接连接到远程主机。但是一旦断开本地与远程主机的连接，pty就会结束所有刚才的进程。
根据网上的资料，Github 仓库的 ssh 连接就采用 pty， Github 不希望用户创建一个可与它的主机交互的 ssh 连接，所以采用这种模式。
Fabric 在默认情况下就采用 pty ，所以想要用 fabric 登录目标主机启动后台进程，必须加上 pty=False。
参考资料 https://github.</description></item><item><title>Python defaultdict结构作计数器的用法</title><link>https://sund.site/posts/2016/10/python-defaultdict%E7%BB%93%E6%9E%84%E4%BD%9C%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E7%94%A8%E6%B3%95/</link><pubDate>Tue, 11 Oct 2016 15:00:16 +0000</pubDate><guid>https://sund.site/posts/2016/10/python-defaultdict%E7%BB%93%E6%9E%84%E4%BD%9C%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E7%94%A8%E6%B3%95/</guid><description>在开发中经常需要用到计数器，当函数foo调用另一个函数bar时，为了确认调用bar之后处理的结果正确性，经常需要使用计数器来统计bar函数里处理成功了多少次。例如：
def foo(): success_num = bar() print success_num def bar(): n = 0 # 假设这个任务要迭代100次. count = 100 try: for i in count: # Do something. n += 1 except: pass finally: return n 但是，这里需要定义多个计数器变量来保存计数。每多一个bar函数就要多定义两次计数器。有没有类似C语言指针一样的方法，可以在foo中定义后直接传给bar，在bar里修改值呢。
众所周知，Python的参数传值实际传的是变量的拷贝，但是对于像字典、列表等非基本数据结构，实际传给参数的是这个数据结构的指针地址，修改指针地址指向的实际值就可以在函数内外实现传递数据的效果了。那么利用这个特性，可以结合python标准库collections里的defaultdict结构来实现一个更方便的计数器：
from collections import defaultdict def foo(): result = defaultdict(int) bar(result) print result def bar(result): count = 100 for i in count: try: # Do something. result[&amp;#39;success&amp;#39;] += 1 except: result[&amp;#39;fail&amp;#39;] += 1 这样，变量result就是存有正确计数和错误计数的字典。</description></item></channel></rss>