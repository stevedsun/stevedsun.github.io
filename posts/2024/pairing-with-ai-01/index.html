<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=en dir=ltr><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>与AI协作编程──测试篇 - The Context Works</title>
<meta name=theme-color><meta name=description content="未来的程序开发范式，将是人与 AI 协作编程。这已经是软件行业不争的事实。像 Windsurf，Cusor，Copilot 之类的编程工具一方面提高了开发效率，另一方面也让代码变得更黑盒，更不易阅读和维护。
我试图浅显地讨论一下哪些软件开发的手段更适合在 AI 时代提高 AI 编写代码的可观测性和维护性。接下来所有以「与 AI 协作编程」为标题的文章都只是抛砖引玉，并未形成系统化方法论。期望任何错误之处，读者不吝赐教。
使用 AI 编写代码有哪些常见问题？
可观测性问题：AI 实现的功能不完备，经常要手动修改片段
AI 生成代码最大的问题在于，它经常引起人类不易察觉的隐蔽错误。当人类使用 prompt 修改代码时，由于 AI 行为的不易观测性，即便修复了一个 bug，也可能导致其他回归问题（引起已有逻辑的错误）。
上下文问题：缺少全局上下文，碎片代码之间缺少联系
由于 Token 数限制或经济上的考虑，很多编辑器会优化输入的内容，这就容易造成大模型错误地理解局部上下文。没有办法处理跨功能模块的业务逻辑。尤其项目变得庞大后，复杂的模块经常依赖其他模块，调整业务逻辑需要重构若干个代码文件。
解决思路
AI 编写代码的核心问题，可以归纳为不可观测性和缺少上下文造成的低维护性。为了解决这两个问题，我们需要先回顾一下传统软件工序如何让代码更易观测和维护。
人类主导的单元测试
单元测试是代码的说明书。复杂的业务逻辑通常需要阅读大量代码才能看懂。但是熟练的程序员会先看单元测试。好的单元测试会把模块的预期输入、输出完整地写进 Case 里。在 Unit Testing Principles, Practices, and Patterns 里，作者认为好的单元测试应该具备：

保护回归。即测试能够防止出现已经修复的问题在回归测试中复现的情况。
抵抗重构。即代码重构后，测试能正确识别出重构是否对已有功能造成影响。
快速反馈。即单元测试容易运行，发现问题能及时定位到错误。
易于维护。 测试不同于业务代码，它的可维护体现在正确处理依赖关系和共享代码。

这些原则最终目的，都是保证被测系统按预期行为运行。
当 AI 和人类合作完成代码时，我个人认为，在编写单元测试这件事上，人类应该主导（80%），AI 辅助（20%），因为单元测试定义了「我期望的行为」。
当单元测试完善后，又反过来指导 AI 实现的真正的业务代码。这时人类占比下降，AI 占据主导。人类反复运行单元测试，同时将测试结果和 prompt 一起传递给 AI，帮助 AI 修正程序的问题。
编写对 AI 友好的测试离不开好的模块设计
在编写好的测试时，也要关注正确的拆分模块。一个好的测试通常是给定输入，验证是否输出预期的结果。而模块如果依赖过多外部环境做分支判断，就会造成测试的输出严重依赖外部状态。这会降低模块的可观测性。
下面两条经验，可以帮助你写出好的代码：


写测试时要测试行为的结果，而不是步骤。写业务代码时，要 AI 写清步骤。
单元测试的「单元」可以不是一个类或函数。而是一组完成一个原子业务逻辑的操作。（当然也有不同的流派支持以类为单位测试，但这不是本文的重点）。为了让 AI 生成的业务代码具有抗重构特性，要验证 AI 的行为结果，而不是验证每一个实现步骤。耦合测试代码和实现步骤会导致业务的修改破坏已有的测试，使得「期望的行为」要不断随着「具体的实现」来修改。"><meta name=author content="Steve Sun"><link rel="preload stylesheet" as=style href=https://sund.site/main.min.css><link rel=preload as=image href=https://sund.site/theme.svg><link rel=preload as=image href=https://sund.site/images/profile.png><link rel=preload as=image href=https://sund.site/github.svg><link rel=preload as=image href=https://sund.site/rss.svg><script defer src=https://sund.site/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://sund.site/favicon.ico><link rel=apple-touch-icon href=https://sund.site/apple-touch-icon.png><meta name=generator content="Hugo 0.136.4"><script async src="https://www.googletagmanager.com/gtag/js?id=G-XJJVVQ0LBH"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XJJVVQ0LBH")}</script><meta itemprop=name content="与AI协作编程──测试篇"><meta itemprop=description content="未来的程序开发范式，将是人与 AI 协作编程。这已经是软件行业不争的事实。像 Windsurf，Cusor，Copilot 之类的编程工具一方面提高了开发效率，另一方面也让代码变得更黑盒，更不易阅读和维护。
我试图浅显地讨论一下哪些软件开发的手段更适合在 AI 时代提高 AI 编写代码的可观测性和维护性。接下来所有以「与 AI 协作编程」为标题的文章都只是抛砖引玉，并未形成系统化方法论。期望任何错误之处，读者不吝赐教。
使用 AI 编写代码有哪些常见问题？ 可观测性问题：AI 实现的功能不完备，经常要手动修改片段
AI 生成代码最大的问题在于，它经常引起人类不易察觉的隐蔽错误。当人类使用 prompt 修改代码时，由于 AI 行为的不易观测性，即便修复了一个 bug，也可能导致其他回归问题（引起已有逻辑的错误）。
上下文问题：缺少全局上下文，碎片代码之间缺少联系
由于 Token 数限制或经济上的考虑，很多编辑器会优化输入的内容，这就容易造成大模型错误地理解局部上下文。没有办法处理跨功能模块的业务逻辑。尤其项目变得庞大后，复杂的模块经常依赖其他模块，调整业务逻辑需要重构若干个代码文件。
解决思路 AI 编写代码的核心问题，可以归纳为不可观测性和缺少上下文造成的低维护性。为了解决这两个问题，我们需要先回顾一下传统软件工序如何让代码更易观测和维护。
人类主导的单元测试 单元测试是代码的说明书。复杂的业务逻辑通常需要阅读大量代码才能看懂。但是熟练的程序员会先看单元测试。好的单元测试会把模块的预期输入、输出完整地写进 Case 里。在 Unit Testing Principles, Practices, and Patterns 里，作者认为好的单元测试应该具备：
保护回归。即测试能够防止出现已经修复的问题在回归测试中复现的情况。 抵抗重构。即代码重构后，测试能正确识别出重构是否对已有功能造成影响。 快速反馈。即单元测试容易运行，发现问题能及时定位到错误。 易于维护。 测试不同于业务代码，它的可维护体现在正确处理依赖关系和共享代码。 这些原则最终目的，都是保证被测系统按预期行为运行。
当 AI 和人类合作完成代码时，我个人认为，在编写单元测试这件事上，人类应该主导（80%），AI 辅助（20%），因为单元测试定义了「我期望的行为」。
当单元测试完善后，又反过来指导 AI 实现的真正的业务代码。这时人类占比下降，AI 占据主导。人类反复运行单元测试，同时将测试结果和 prompt 一起传递给 AI，帮助 AI 修正程序的问题。
编写对 AI 友好的测试离不开好的模块设计 在编写好的测试时，也要关注正确的拆分模块。一个好的测试通常是给定输入，验证是否输出预期的结果。而模块如果依赖过多外部环境做分支判断，就会造成测试的输出严重依赖外部状态。这会降低模块的可观测性。
下面两条经验，可以帮助你写出好的代码：
写测试时要测试行为的结果，而不是步骤。写业务代码时，要 AI 写清步骤。
单元测试的「单元」可以不是一个类或函数。而是一组完成一个原子业务逻辑的操作。（当然也有不同的流派支持以类为单位测试，但这不是本文的重点）。为了让 AI 生成的业务代码具有抗重构特性，要验证 AI 的行为结果，而不是验证每一个实现步骤。耦合测试代码和实现步骤会导致业务的修改破坏已有的测试，使得「期望的行为」要不断随着「具体的实现」来修改。"><meta itemprop=datePublished content="2024-12-11T17:02:43+08:00"><meta itemprop=dateModified content="2024-12-11T17:02:43+08:00"><meta itemprop=wordCount content="94"><meta itemprop=keywords content="Ai,Unit Test"><meta property="og:url" content="https://sund.site/posts/2024/pairing-with-ai-01/"><meta property="og:site_name" content="The Context Works"><meta property="og:title" content="与AI协作编程──测试篇"><meta property="og:description" content="未来的程序开发范式，将是人与 AI 协作编程。这已经是软件行业不争的事实。像 Windsurf，Cusor，Copilot 之类的编程工具一方面提高了开发效率，另一方面也让代码变得更黑盒，更不易阅读和维护。
我试图浅显地讨论一下哪些软件开发的手段更适合在 AI 时代提高 AI 编写代码的可观测性和维护性。接下来所有以「与 AI 协作编程」为标题的文章都只是抛砖引玉，并未形成系统化方法论。期望任何错误之处，读者不吝赐教。
使用 AI 编写代码有哪些常见问题？ 可观测性问题：AI 实现的功能不完备，经常要手动修改片段
AI 生成代码最大的问题在于，它经常引起人类不易察觉的隐蔽错误。当人类使用 prompt 修改代码时，由于 AI 行为的不易观测性，即便修复了一个 bug，也可能导致其他回归问题（引起已有逻辑的错误）。
上下文问题：缺少全局上下文，碎片代码之间缺少联系
由于 Token 数限制或经济上的考虑，很多编辑器会优化输入的内容，这就容易造成大模型错误地理解局部上下文。没有办法处理跨功能模块的业务逻辑。尤其项目变得庞大后，复杂的模块经常依赖其他模块，调整业务逻辑需要重构若干个代码文件。
解决思路 AI 编写代码的核心问题，可以归纳为不可观测性和缺少上下文造成的低维护性。为了解决这两个问题，我们需要先回顾一下传统软件工序如何让代码更易观测和维护。
人类主导的单元测试 单元测试是代码的说明书。复杂的业务逻辑通常需要阅读大量代码才能看懂。但是熟练的程序员会先看单元测试。好的单元测试会把模块的预期输入、输出完整地写进 Case 里。在 Unit Testing Principles, Practices, and Patterns 里，作者认为好的单元测试应该具备：
保护回归。即测试能够防止出现已经修复的问题在回归测试中复现的情况。 抵抗重构。即代码重构后，测试能正确识别出重构是否对已有功能造成影响。 快速反馈。即单元测试容易运行，发现问题能及时定位到错误。 易于维护。 测试不同于业务代码，它的可维护体现在正确处理依赖关系和共享代码。 这些原则最终目的，都是保证被测系统按预期行为运行。
当 AI 和人类合作完成代码时，我个人认为，在编写单元测试这件事上，人类应该主导（80%），AI 辅助（20%），因为单元测试定义了「我期望的行为」。
当单元测试完善后，又反过来指导 AI 实现的真正的业务代码。这时人类占比下降，AI 占据主导。人类反复运行单元测试，同时将测试结果和 prompt 一起传递给 AI，帮助 AI 修正程序的问题。
编写对 AI 友好的测试离不开好的模块设计 在编写好的测试时，也要关注正确的拆分模块。一个好的测试通常是给定输入，验证是否输出预期的结果。而模块如果依赖过多外部环境做分支判断，就会造成测试的输出严重依赖外部状态。这会降低模块的可观测性。
下面两条经验，可以帮助你写出好的代码：
写测试时要测试行为的结果，而不是步骤。写业务代码时，要 AI 写清步骤。
单元测试的「单元」可以不是一个类或函数。而是一组完成一个原子业务逻辑的操作。（当然也有不同的流派支持以类为单位测试，但这不是本文的重点）。为了让 AI 生成的业务代码具有抗重构特性，要验证 AI 的行为结果，而不是验证每一个实现步骤。耦合测试代码和实现步骤会导致业务的修改破坏已有的测试，使得「期望的行为」要不断随着「具体的实现」来修改。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-11T17:02:43+08:00"><meta property="article:modified_time" content="2024-12-11T17:02:43+08:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Unit Test"><meta name=twitter:card content="summary"><meta name=twitter:title content="与AI协作编程──测试篇"><meta name=twitter:description content="未来的程序开发范式，将是人与 AI 协作编程。这已经是软件行业不争的事实。像 Windsurf，Cusor，Copilot 之类的编程工具一方面提高了开发效率，另一方面也让代码变得更黑盒，更不易阅读和维护。
我试图浅显地讨论一下哪些软件开发的手段更适合在 AI 时代提高 AI 编写代码的可观测性和维护性。接下来所有以「与 AI 协作编程」为标题的文章都只是抛砖引玉，并未形成系统化方法论。期望任何错误之处，读者不吝赐教。
使用 AI 编写代码有哪些常见问题？ 可观测性问题：AI 实现的功能不完备，经常要手动修改片段
AI 生成代码最大的问题在于，它经常引起人类不易察觉的隐蔽错误。当人类使用 prompt 修改代码时，由于 AI 行为的不易观测性，即便修复了一个 bug，也可能导致其他回归问题（引起已有逻辑的错误）。
上下文问题：缺少全局上下文，碎片代码之间缺少联系
由于 Token 数限制或经济上的考虑，很多编辑器会优化输入的内容，这就容易造成大模型错误地理解局部上下文。没有办法处理跨功能模块的业务逻辑。尤其项目变得庞大后，复杂的模块经常依赖其他模块，调整业务逻辑需要重构若干个代码文件。
解决思路 AI 编写代码的核心问题，可以归纳为不可观测性和缺少上下文造成的低维护性。为了解决这两个问题，我们需要先回顾一下传统软件工序如何让代码更易观测和维护。
人类主导的单元测试 单元测试是代码的说明书。复杂的业务逻辑通常需要阅读大量代码才能看懂。但是熟练的程序员会先看单元测试。好的单元测试会把模块的预期输入、输出完整地写进 Case 里。在 Unit Testing Principles, Practices, and Patterns 里，作者认为好的单元测试应该具备：
保护回归。即测试能够防止出现已经修复的问题在回归测试中复现的情况。 抵抗重构。即代码重构后，测试能正确识别出重构是否对已有功能造成影响。 快速反馈。即单元测试容易运行，发现问题能及时定位到错误。 易于维护。 测试不同于业务代码，它的可维护体现在正确处理依赖关系和共享代码。 这些原则最终目的，都是保证被测系统按预期行为运行。
当 AI 和人类合作完成代码时，我个人认为，在编写单元测试这件事上，人类应该主导（80%），AI 辅助（20%），因为单元测试定义了「我期望的行为」。
当单元测试完善后，又反过来指导 AI 实现的真正的业务代码。这时人类占比下降，AI 占据主导。人类反复运行单元测试，同时将测试结果和 prompt 一起传递给 AI，帮助 AI 修正程序的问题。
编写对 AI 友好的测试离不开好的模块设计 在编写好的测试时，也要关注正确的拆分模块。一个好的测试通常是给定输入，验证是否输出预期的结果。而模块如果依赖过多外部环境做分支判断，就会造成测试的输出严重依赖外部状态。这会降低模块的可观测性。
下面两条经验，可以帮助你写出好的代码：
写测试时要测试行为的结果，而不是步骤。写业务代码时，要 AI 写清步骤。
单元测试的「单元」可以不是一个类或函数。而是一组完成一个原子业务逻辑的操作。（当然也有不同的流派支持以类为单位测试，但这不是本文的重点）。为了让 AI 生成的业务代码具有抗重构特性，要验证 AI 的行为结果，而不是验证每一个实现步骤。耦合测试代码和实现步骤会导致业务的修改破坏已有的测试，使得「期望的行为」要不断随着「具体的实现」来修改。"><link rel=canonical href=https://sund.site/posts/2024/pairing-with-ai-01/><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2639081419131654" crossorigin=anonymous></script></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center"><div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center"><a class="-translate-y-[1px] text-2xl font-medium" href=https://sund.site/>The Context Works</a><div class="btn-dark text-[0] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a>
<a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/blogroll/>Blogroll</a></nav><nav class="mt-12 flex justify-center space-x-10 rtl:space-x-reverse dark:invert ltr:lg:ml-14 rtl:lg:mr-14 lg:mt-0 lg:items-center"><a class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/stevedsun target=_blank rel=me>github
</a><a class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=https://sund.site/index.xml target=_blank rel=alternate>rss</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"><article><header class=mb-14><h1 class="!my-0 pb-2.5">与AI协作编程──测试篇</h1><div class="text-xs antialiased opacity-60"><time>Dec 11, 2024</time></div></header><section><p>未来的程序开发范式，将是人与 AI 协作编程。这已经是软件行业不争的事实。像 Windsurf，Cusor，Copilot 之类的编程工具一方面提高了开发效率，另一方面也让代码变得更黑盒，更不易阅读和维护。</p><p>我试图浅显地讨论一下哪些软件开发的手段更适合在 AI 时代提高 AI 编写代码的可观测性和维护性。接下来所有以「与 AI 协作编程」为标题的文章都只是抛砖引玉，并未形成系统化方法论。期望任何错误之处，读者不吝赐教。</p><h2 id=使用-ai-编写代码有哪些常见问题>使用 AI 编写代码有哪些常见问题？</h2><p><strong>可观测性问题：AI 实现的功能不完备，经常要手动修改片段</strong></p><p>AI 生成代码最大的问题在于，它经常引起人类不易察觉的隐蔽错误。当人类使用 prompt 修改代码时，由于 AI 行为的不易观测性，即便修复了一个 bug，也可能导致其他回归问题（引起已有逻辑的错误）。</p><p><strong>上下文问题：缺少全局上下文，碎片代码之间缺少联系</strong></p><p>由于 Token 数限制或经济上的考虑，很多编辑器会优化输入的内容，这就容易造成大模型错误地理解局部上下文。没有办法处理跨功能模块的业务逻辑。尤其项目变得庞大后，复杂的模块经常依赖其他模块，调整业务逻辑需要重构若干个代码文件。</p><h2 id=解决思路>解决思路</h2><p>AI 编写代码的核心问题，可以归纳为不可观测性和缺少上下文造成的低维护性。为了解决这两个问题，我们需要先回顾一下传统软件工序如何让代码更易观测和维护。</p><h3 id=人类主导的单元测试>人类主导的单元测试</h3><p>单元测试是代码的说明书。复杂的业务逻辑通常需要阅读大量代码才能看懂。但是熟练的程序员会先看单元测试。好的单元测试会把模块的预期输入、输出完整地写进 Case 里。在 <a href=https://www.amazon.com/Unit-Testing-Principles-Practices-Patterns/dp/1617296279>Unit Testing Principles, Practices, and Patterns</a> 里，作者认为好的单元测试应该具备：</p><ul><li><strong>保护回归</strong>。即测试能够防止出现已经修复的问题在回归测试中复现的情况。</li><li><strong>抵抗重构</strong>。即代码重构后，测试能正确识别出重构是否对已有功能造成影响。</li><li><strong>快速反馈</strong>。即单元测试容易运行，发现问题能及时定位到错误。</li><li><strong>易于维护</strong>。 测试不同于业务代码，它的可维护体现在正确处理依赖关系和共享代码。</li></ul><p>这些原则最终目的，都是保证被测系统按预期行为运行。</p><p>当 AI 和人类合作完成代码时，我个人认为，在编写单元测试这件事上，人类应该主导（80%），AI 辅助（20%），因为单元测试定义了「我期望的行为」。</p><p>当单元测试完善后，又反过来指导 AI 实现的真正的业务代码。这时人类占比下降，AI 占据主导。人类反复运行单元测试，同时将测试结果和 prompt 一起传递给 AI，帮助 AI 修正程序的问题。</p><h3 id=编写对-ai-友好的测试离不开好的模块设计>编写对 AI 友好的测试离不开好的模块设计</h3><p>在编写好的测试时，也要关注正确的拆分模块。一个好的测试通常是给定输入，验证是否输出预期的结果。而模块如果依赖过多外部环境做分支判断，就会造成测试的输出严重依赖外部状态。这会降低模块的可观测性。</p><p>下面两条经验，可以帮助你写出好的代码：</p><ol><li><p>写测试时要测试行为的结果，而不是步骤。写业务代码时，要 AI 写清步骤。</p><p>单元测试的「单元」可以不是一个类或函数。而是一组完成一个原子业务逻辑的操作。（当然也有不同的流派支持以类为单位测试，但这不是本文的重点）。为了让 AI 生成的业务代码具有抗重构特性，要验证 AI 的行为结果，而不是验证每一个实现步骤。耦合测试代码和实现步骤会导致业务的修改破坏已有的测试，使得「期望的行为」要不断随着「具体的实现」来修改。</p><p>当 AI 开始写业务逻辑后，应该以步骤驱动的方式逐步实现，期间，人类可以针对某一步骤修正 AI 的代码逻辑。但切忌破坏测试的逻辑。</p></li><li><p>无状态的代码（函数式）最容易测试</p><p>因为它的输出具有不变性。应该让核心代码尽量无状态，将状态、外部系统依赖放在应用服务层。而把深且不易理解的核心逻辑，放在领域服务层。这里的细节可以参考 DDD（Domain Driven Design）的思想。</p><p><img src=/images/pairing-with-ai-01/functional_core.png alt=functional_core.png></p></li></ol><h2 id=小结>小结</h2><p>这篇文章作为一系列人类与 AI 协作编程话题的开头，从测试角度试图缓解 AI 生成代码的可观测性问题。</p><p>在后边的文章里，我希望从架构设计角度，讨论一下如何设计 AI 友好的、易于维护上下文的架构。</p><p>文章内容会随着时间的推移，持续更新，欢迎讨论。</p></section><footer class="mt-12 flex flex-wrap"><a class="mb-1.5 ltr:mr-1.5 rtl:ml-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://sund.site/tags/ai>ai</a>
<a class="mb-1.5 ltr:mr-1.5 rtl:ml-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://sund.site/tags/unit-test>unit test</a></footer><nav class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"><a class="ltr:ml-auto rtl:mr-auto justify-end pl-3" href=https://sund.site/posts/2024/go-dependency-inject/><span>Go 语言的依赖倒置</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a></nav><div class=mt-24 id=graphcomment></div><script type=text/javascript>var __semio__params={graphcommentId:"steve-sun",behaviour:{}};function __semio__onload(){__semio__gc_graphlogin(__semio__params)}(function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.onload=__semio__onload,e.defer=!0,e.src="https://integration.graphcomment.com/gc_graphlogin.js?"+Date.now(),(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)})()</script></article></main><footer class="mx-auto flex h-[4.5rem] max-w-[--w] items-center px-8 text-xs uppercase tracking-wider opacity-60"><div class=mr-auto>Copyright © 2024, Steve Sun; all rights reserved.</div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>powered by hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>hugo-paper</a></footer></body></html>