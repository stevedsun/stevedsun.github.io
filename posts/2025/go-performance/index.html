<!doctype html><html lang=zh-CN><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://sund.site/favicon.ico><title>Go服务端性能的一般解决思路 | Steve Sun</title>
<meta name=title content="Go服务端性能的一般解决思路"><meta name=description content='最近遇到一个性能问题，客户反馈，在他们的 IPC 设备后台有两个 Go 语言编写的服务进程占用内存一直在上涨，最大时候达到了总内存的 40% 。其中一个进程就是我们日志采集 Agent。
我首先怀疑是内存泄漏，因为过去发生过 goroutine 阻塞造成的内存泄漏（我在Go 内存泄漏常见模式中讨论过)，所以我先针对所有创建和释放 goroutine 的地方进行排查。
在上一次教训之后，我们对代码单元测试层面做了 goruntine 内存泄漏的检测——使用go.uber.org/goleak。只需要在单元测试开头加上一句:
func TestXXX(t *testing.T) {
    defer goleak.VerifyNone(t)
    // ...
}
它就会在测试结束后自动检查是否有残留的 goroutine 协程。对于一些延迟执行的后台 goroutine 可以在单元测试里用 wait 或者 sleep 等待后台释放再结束测试用例。
经过第一轮排查可以排除代码本身 goroutine 造成的问题。于是我把注意力转向了另一个地方：定时任务。
根据客户反馈，在无任何前台操作的情况下，内存也会缓慢上升。
在我们代码里，使用了github.com/robfig/cron/v3这个第三方包，它的作用是编排定时任务。用法是
c = cron.New()
c.AddFunc("@every 10s", callbackFunc)
这种结构定义一个定时任务。它的实现也基于 goroutine，所以我把 go 自带的 pprof 加入到 main.go 的依赖中，重新编译了项目二进制文件并部署到测试环境上（使用跟用户相同的硬件配置）。这样启动项目后就可以在特定端口获取内存信息。（关于 pprof，你可以参考 Profiling Go Programs）
我使用 pprof 的接口获取了不同时间间隔的 heap 数据
curl -o heap.1.out http://127.0.0.1:6060/debug/pprof/heap
然后使用
go tool pprof -http=:8099 -base heap.1.out heap.2.out
比较两次结果的差异，在 Web UI 上选择 In Use Space 选项，可以查看到哪些内存没有释放。
虽然经过第二轮排查，依然没有发现内存泄漏。但这一次我注意到服务中的一个定时任务会每隔 10 秒执行一次，执行过程中 CPU 占用率明显上升。在这个任务的代码里，它使用了github.com/shirou/gopsutil/process这个第三方库来查询系统进程 ID 和进程名等信息。'><meta name=keywords content="Go,"><link rel=canonical href=https://sund.site/posts/2025/go-performance/><meta property="og:url" content="https://sund.site/posts/2025/go-performance/"><meta property="og:site_name" content="Steve Sun"><meta property="og:title" content="Go服务端性能的一般解决思路"><meta property="og:description" content='最近遇到一个性能问题，客户反馈，在他们的 IPC 设备后台有两个 Go 语言编写的服务进程占用内存一直在上涨，最大时候达到了总内存的 40% 。其中一个进程就是我们日志采集 Agent。
我首先怀疑是内存泄漏，因为过去发生过 goroutine 阻塞造成的内存泄漏（我在Go 内存泄漏常见模式中讨论过)，所以我先针对所有创建和释放 goroutine 的地方进行排查。
在上一次教训之后，我们对代码单元测试层面做了 goruntine 内存泄漏的检测——使用go.uber.org/goleak。只需要在单元测试开头加上一句:
func TestXXX(t *testing.T) { defer goleak.VerifyNone(t) // ... } 它就会在测试结束后自动检查是否有残留的 goroutine 协程。对于一些延迟执行的后台 goroutine 可以在单元测试里用 wait 或者 sleep 等待后台释放再结束测试用例。
经过第一轮排查可以排除代码本身 goroutine 造成的问题。于是我把注意力转向了另一个地方：定时任务。
根据客户反馈，在无任何前台操作的情况下，内存也会缓慢上升。
在我们代码里，使用了github.com/robfig/cron/v3这个第三方包，它的作用是编排定时任务。用法是
c = cron.New() c.AddFunc("@every 10s", callbackFunc) 这种结构定义一个定时任务。它的实现也基于 goroutine，所以我把 go 自带的 pprof 加入到 main.go 的依赖中，重新编译了项目二进制文件并部署到测试环境上（使用跟用户相同的硬件配置）。这样启动项目后就可以在特定端口获取内存信息。（关于 pprof，你可以参考 Profiling Go Programs）
我使用 pprof 的接口获取了不同时间间隔的 heap 数据
curl -o heap.1.out http://127.0.0.1:6060/debug/pprof/heap 然后使用
go tool pprof -http=:8099 -base heap.1.out heap.2.out 比较两次结果的差异，在 Web UI 上选择 In Use Space 选项，可以查看到哪些内存没有释放。
虽然经过第二轮排查，依然没有发现内存泄漏。但这一次我注意到服务中的一个定时任务会每隔 10 秒执行一次，执行过程中 CPU 占用率明显上升。在这个任务的代码里，它使用了github.com/shirou/gopsutil/process这个第三方库来查询系统进程 ID 和进程名等信息。'><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-06T10:35:41+08:00"><meta property="article:modified_time" content="2025-05-06T10:35:41+08:00"><meta property="article:tag" content="Go"><meta property="og:image" content="https://sund.site/images/share.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://sund.site/images/share.png"><meta name=twitter:title content="Go服务端性能的一般解决思路"><meta name=twitter:description content='最近遇到一个性能问题，客户反馈，在他们的 IPC 设备后台有两个 Go 语言编写的服务进程占用内存一直在上涨，最大时候达到了总内存的 40% 。其中一个进程就是我们日志采集 Agent。
我首先怀疑是内存泄漏，因为过去发生过 goroutine 阻塞造成的内存泄漏（我在Go 内存泄漏常见模式中讨论过)，所以我先针对所有创建和释放 goroutine 的地方进行排查。
在上一次教训之后，我们对代码单元测试层面做了 goruntine 内存泄漏的检测——使用go.uber.org/goleak。只需要在单元测试开头加上一句:
func TestXXX(t *testing.T) { defer goleak.VerifyNone(t) // ... } 它就会在测试结束后自动检查是否有残留的 goroutine 协程。对于一些延迟执行的后台 goroutine 可以在单元测试里用 wait 或者 sleep 等待后台释放再结束测试用例。
经过第一轮排查可以排除代码本身 goroutine 造成的问题。于是我把注意力转向了另一个地方：定时任务。
根据客户反馈，在无任何前台操作的情况下，内存也会缓慢上升。
在我们代码里，使用了github.com/robfig/cron/v3这个第三方包，它的作用是编排定时任务。用法是
c = cron.New() c.AddFunc("@every 10s", callbackFunc) 这种结构定义一个定时任务。它的实现也基于 goroutine，所以我把 go 自带的 pprof 加入到 main.go 的依赖中，重新编译了项目二进制文件并部署到测试环境上（使用跟用户相同的硬件配置）。这样启动项目后就可以在特定端口获取内存信息。（关于 pprof，你可以参考 Profiling Go Programs）
我使用 pprof 的接口获取了不同时间间隔的 heap 数据
curl -o heap.1.out http://127.0.0.1:6060/debug/pprof/heap 然后使用
go tool pprof -http=:8099 -base heap.1.out heap.2.out 比较两次结果的差异，在 Web UI 上选择 In Use Space 选项，可以查看到哪些内存没有释放。
虽然经过第二轮排查，依然没有发现内存泄漏。但这一次我注意到服务中的一个定时任务会每隔 10 秒执行一次，执行过程中 CPU 占用率明显上升。在这个任务的代码里，它使用了github.com/shirou/gopsutil/process这个第三方库来查询系统进程 ID 和进程名等信息。'><meta itemprop=name content="Go服务端性能的一般解决思路"><meta itemprop=description content='最近遇到一个性能问题，客户反馈，在他们的 IPC 设备后台有两个 Go 语言编写的服务进程占用内存一直在上涨，最大时候达到了总内存的 40% 。其中一个进程就是我们日志采集 Agent。
我首先怀疑是内存泄漏，因为过去发生过 goroutine 阻塞造成的内存泄漏（我在Go 内存泄漏常见模式中讨论过)，所以我先针对所有创建和释放 goroutine 的地方进行排查。
在上一次教训之后，我们对代码单元测试层面做了 goruntine 内存泄漏的检测——使用go.uber.org/goleak。只需要在单元测试开头加上一句:
func TestXXX(t *testing.T) { defer goleak.VerifyNone(t) // ... } 它就会在测试结束后自动检查是否有残留的 goroutine 协程。对于一些延迟执行的后台 goroutine 可以在单元测试里用 wait 或者 sleep 等待后台释放再结束测试用例。
经过第一轮排查可以排除代码本身 goroutine 造成的问题。于是我把注意力转向了另一个地方：定时任务。
根据客户反馈，在无任何前台操作的情况下，内存也会缓慢上升。
在我们代码里，使用了github.com/robfig/cron/v3这个第三方包，它的作用是编排定时任务。用法是
c = cron.New() c.AddFunc("@every 10s", callbackFunc) 这种结构定义一个定时任务。它的实现也基于 goroutine，所以我把 go 自带的 pprof 加入到 main.go 的依赖中，重新编译了项目二进制文件并部署到测试环境上（使用跟用户相同的硬件配置）。这样启动项目后就可以在特定端口获取内存信息。（关于 pprof，你可以参考 Profiling Go Programs）
我使用 pprof 的接口获取了不同时间间隔的 heap 数据
curl -o heap.1.out http://127.0.0.1:6060/debug/pprof/heap 然后使用
go tool pprof -http=:8099 -base heap.1.out heap.2.out 比较两次结果的差异，在 Web UI 上选择 In Use Space 选项，可以查看到哪些内存没有释放。
虽然经过第二轮排查，依然没有发现内存泄漏。但这一次我注意到服务中的一个定时任务会每隔 10 秒执行一次，执行过程中 CPU 占用率明显上升。在这个任务的代码里，它使用了github.com/shirou/gopsutil/process这个第三方库来查询系统进程 ID 和进程名等信息。'><meta itemprop=datePublished content="2025-05-06T10:35:41+08:00"><meta itemprop=dateModified content="2025-05-06T10:35:41+08:00"><meta itemprop=wordCount content="123"><meta itemprop=image content="https://sund.site/images/share.png"><meta itemprop=keywords content="Go"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width-max:720px;--font-primary:Verdana, sans-serif;--font-secondary:monospace;--font-size-primary:1em;--font-size-secondary:0.8em;--body-bg-color:#fcfcfc;--bold-text-color:#222;--body-text-color:#444;--link-color:#3273dc;--link-visited-color:#8b6fcb;--table-border-color:#f2f2f2;--table-th-bg-color:#f2f2f2;--img-border-color:#f2f2f2;--code-bg-color:#f2f2f2;--code-text-color:#222;--blockquote-border-color:#666;--blockquote-text-color:#666;--upvoted-color:#FA8072}@media(prefers-color-scheme:dark){:root{--body-bg-color:#1c1c1c;--bold-text-color:#eee;--body-text-color:#ddd;--link-color:#8cc2dd;--link-visited-color:#c3b1ee;--table-border-color:#999;--table-th-bg-color:#999;--img-border-color:#999;--code-bg-color:#555;--code-text-color:#ddd;--blockquote-border-color:#ccc;--blockquote-text-color:#ccc}}body{font-family:var(--font-primary);font-size:var(--font-size-primary);margin:auto;padding:20px;max-width:var(--width-max);text-align:left;background-color:var(--body-bg-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--body-text-color)}h1,h2,h3,h4,h5,h6,strong,b{color:var(--bold-text-color)}h1,h2,h3,h4,h5,h6{margin:16px 0}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}.title{text-decoration:none;border:0}.title:hover{text-decoration:none}.title span{font-weight:400}nav a{margin-right:8px}textarea{width:100%;font-size:16px}input{font-size:14px}content{line-height:1.6}table{width:100%;border-collapse:collapse;border:1px solid var(--table-border-color);border-radius:4px}th,td{border:1px solid var(--table-border-color);padding:4px}th{background-color:var(--table-th-bg-color)}hr{border:0;border-top:1px dashed}img{max-width:100%;display:block;margin-left:auto;margin-right:auto;border:1px solid var(--img-border-color);border-radius:4px;content-visibility:auto;loading:lazy}img[src*="#minipic"]{max-width:50%;margin-left:0;margin-right:auto}i{font-style:normal}time{font-family:var(--font-secondary);font-size:15px}code{font-family:var(--font-secondary);background-color:var(--code-bg-color);color:var(--code-text-color);padding:2px;border-radius:4px}pre code{display:block;padding:16px;white-space:pre-wrap;overflow-x:auto}div.highlight pre{border-radius:4px}div.highlight code{background-color:var(--code-bg-color);color:var(--code-text-color)}blockquote{border-left:2px solid var(--blockquote-border-color);color:var(--blockquote-text-color);margin:0;padding-left:16px;font-style:normal}blockquote p{margin:0}footer{padding:25px 0;text-align:center;font-size:var(--font-size-secondary)}ul li:has(input){list-style-type:none;margin-left:-25.5px}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li span.grouped{flex:0 0 80px}ul.blog-posts li a:visited{color:var(--link-visited-color)}div.toc{position:fixed;top:50%;left:calc((100vw + var(--width-max))/2);transform:translateY(-50%);width:calc((90vw - var(--width-max))/2);max-height:80vh;overflow-y:auto;padding:20px 8px;z-index:99;&::-webkit-scrollbar { display:none; } -ms-overflow-style:none;scrollbar-width:none}div.toc ul{list-style-type:none;padding-left:0}div.toc ul li{margin:8px 0}div.toc ul li a{text-decoration:none;color:var(--blockquote-text-color)}div.toc ul li a:hover{color:var(--link-color)}button.upvote-btn{margin:0;padding:0;border:none;background:0 0;cursor:pointer;display:flex;flex-direction:column;align-items:center;color:var(--body-text-color)}button.upvoted{color:var(--upvoted-color)}span.upvote-count{margin-top:-4px;font-size:smaller}@media(max-width:500px){img[src*="#minipic"]{max-width:100%;margin-left:auto;margin-right:auto}div.toc{display:none}}</style><link rel=stylesheet href=https://chinese-fonts-cdn.deno.dev/packages/lxgwwenkai/dist/LXGWWenKai-Regular/result.css><style>body,div.post-body,h1,h2,h3,h4{font-family:lxgw wenkai,sans-serif;font-size:18px}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-XJJVVQ0LBH"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XJJVVQ0LBH")</script></head><body><header><a href=/ class=title><h1>Steve Sun</h1></a><nav><a href=/>Home</a>
<a href=/friends/>Friends</a>
<a href=/posts/>Posts</a></nav></header><main><h1>Go服务端性能的一般解决思路</h1><p><i><time datetime=2025-05-06 pubdate>06 May, 2025</time></i></p><content><p>最近遇到一个性能问题，客户反馈，在他们的 IPC 设备后台有两个 Go 语言编写的服务进程占用内存一直在上涨，最大时候达到了总内存的 40% 。其中一个进程就是我们日志采集 Agent。</p><p>我首先怀疑是内存泄漏，因为过去发生过 goroutine 阻塞造成的内存泄漏（我在<a href=/posts/2023/goroutine-leak/>Go 内存泄漏常见模式</a>中讨论过)，所以我先针对所有创建和释放 goroutine 的地方进行排查。</p><p>在上一次教训之后，我们对代码单元测试层面做了 goruntine 内存泄漏的检测——使用<code>go.uber.org/goleak</code>。只需要在单元测试开头加上一句:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#66d9ef>func</span> <span style=color:#a6e22e>TestXXX</span>(<span style=color:#a6e22e>t</span> <span style=color:#f92672>*</span><span style=color:#a6e22e>testing</span>.<span style=color:#a6e22e>T</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>defer</span> <span style=color:#a6e22e>goleak</span>.<span style=color:#a6e22e>VerifyNone</span>(<span style=color:#a6e22e>t</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>}
</span></span></code></pre></div><p>它就会在测试结束后自动检查是否有残留的 goroutine 协程。对于一些延迟执行的后台 goroutine 可以在单元测试里用 wait 或者 sleep 等待后台释放再结束测试用例。</p><p>经过第一轮排查可以排除代码本身 goroutine 造成的问题。于是我把注意力转向了另一个地方：定时任务。</p><p>根据客户反馈，在无任何前台操作的情况下，内存也会缓慢上升。</p><p>在我们代码里，使用了<code>github.com/robfig/cron/v3</code>这个第三方包，它的作用是编排定时任务。用法是</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>c</span> = <span style=color:#a6e22e>cron</span>.<span style=color:#a6e22e>New</span>()
</span></span><span style=display:flex><span><span style=color:#a6e22e>c</span>.<span style=color:#a6e22e>AddFunc</span>(<span style=color:#e6db74>&#34;@every 10s&#34;</span>, <span style=color:#a6e22e>callbackFunc</span>)
</span></span></code></pre></div><p>这种结构定义一个定时任务。它的实现也基于 goroutine，所以我把 go 自带的 pprof 加入到 main.go 的依赖中，重新编译了项目二进制文件并部署到测试环境上（使用跟用户相同的硬件配置）。这样启动项目后就可以在特定端口获取内存信息。（关于 pprof，你可以参考 <a href=https://go.dev/blog/pprof>Profiling Go Programs</a>）</p><p>我使用 pprof 的接口获取了不同时间间隔的 heap 数据</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>curl</span> <span style=color:#f92672>-</span><span style=color:#a6e22e>o</span> <span style=color:#a6e22e>heap</span><span style=color:#ae81ff>.1</span>.<span style=color:#a6e22e>out</span> <span style=color:#a6e22e>http</span>:<span style=color:#75715e>//127.0.0.1:6060/debug/pprof/heap
</span></span></span></code></pre></div><p>然后使用</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#66d9ef>go</span> <span style=color:#a6e22e>tool</span> <span style=color:#a6e22e>pprof</span> <span style=color:#f92672>-</span><span style=color:#a6e22e>http</span>=:<span style=color:#ae81ff>8099</span> <span style=color:#f92672>-</span><span style=color:#a6e22e>base</span> <span style=color:#a6e22e>heap</span><span style=color:#ae81ff>.1</span>.<span style=color:#a6e22e>out</span> <span style=color:#a6e22e>heap</span><span style=color:#ae81ff>.2</span>.<span style=color:#a6e22e>out</span>
</span></span></code></pre></div><p>比较两次结果的差异，在 Web UI 上选择 In Use Space 选项，可以查看到哪些内存没有释放。</p><p>虽然经过第二轮排查，依然没有发现内存泄漏。但这一次我注意到服务中的一个定时任务会每隔 10 秒执行一次，执行过程中 CPU 占用率明显上升。在这个任务的代码里，它使用了<code>github.com/shirou/gopsutil/process</code>这个第三方库来查询系统进程 ID 和进程名等信息。</p><p>我查看它的源码后发现，这个库查询进程 ID 的方式，是把系统中所有的进程信息加载到内存中，然后匹配 ID 或者名称。因此，如果用户设备上的进程过多，就会每次查询时占用大量内存。</p><p>在一个 10 秒执行一次的定时任务中调用这个库，显然是非常低效的。</p><p>经过与客户进一步沟通，我们发现出现内存过高的两个进程中，另一个进程也有 CPU 占用过高的现象。于是我们让客户把 <code>top</code> 命令的截图发给我们。在看到截图的一瞬间，问题的真相就浮出水面了:</p><p>客户使用的 IPC 设备是性能比较低的版本，虽然内存较大，但 CPU 性能捉急。如果有多个进程同时执行后台任务，CPU 就会周期性打满，造成任务阻塞。而我们使用的第三方库基于 goroutine 来实现定时任务。在上一个任务被阻塞时，下一个任务依然会继续创建新的后台 goroutine，导致内存中的 goroutine 协程堆积地越来越多。</p><p>这是一个定时任务的 CPU 占用过高，间隔过短，造成的 goroutine 阻塞问题。</p><p>知道了原因，剩下的工作就是优化代码逻辑、更新版本、跟客户解释原因……</p><p>以上就是这次排查 Go 服务性能问题的过程，如果你也遇到类似情况，希望对你有所帮助。</p></content><p><a href=https://sund.site/tags/go/>#Go</a></p><div class=toc><nav id=TableOfContents></nav></div></main><footer>Subscribe via <a href=/index.xml>RSS</a>.<br>Made with
<a href=https://github.com/rokcso/hugo-bearblog-neo/>Hugo Bear Neo</a>.<br>Copyright © 2013-2025, Steve Sun.
🗺️ <a href=/sitemap.xml>Sitemap</a>.</footer></body></html>