<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on 電波障害</title><link>https://sund.site/categories/python/</link><description>Recent content in Python on 電波障害</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2024, Steve Sun; all rights reserved.</copyright><lastBuildDate>Thu, 19 Jan 2023 08:05:27 +0800</lastBuildDate><atom:link href="https://sund.site/categories/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Python 依赖管理工具的研究</title><link>https://sund.site/posts/2023/python-packaging/</link><pubDate>Thu, 19 Jan 2023 08:05:27 +0800</pubDate><guid>https://sund.site/posts/2023/python-packaging/</guid><description>太长不读 如果你从事工程项目，poetry 是目前最好的方案，但是如果你不喜欢 Python 的 virtualenv，可以试试 pdm。
混乱的 Python Python 的依赖管理工具 pip 一直被众多开发者吐槽。从我个人角度，pip 有三点致命缺陷：
无法解决 Python 依赖环境的隔离问题 依赖管理文件 requirements.txt 无法真正开箱即用 打包部署非常麻烦，需要手动配置 环境隔离问题 Python 的依赖库可以安装到系统全局，也可以安装到用户目录（/home/${USER}/.local）。但如果你同时管理多个 Python 项目，就需要将不同项目的依赖拆分到不同的文件夹分开管理。
传统方式是基于 virtualenv 创建隔离的 Python bin 文件和项目依赖的虚拟环境（所谓虚拟环境并不是虚拟机，只是个绑定 terminal session 的命令环境）。这种方式的缺点是：
开发者需要经常关注“我现在处于哪个项目目录？我需要切换到当前虚拟环境里吗？”之类的问题。 virtualenv 只解决环境隔离，但是无法同步更新依赖文件、打包发布。 依赖安装问题 Python 管理依赖的手段，最早是手动执行pip install xxx来安装依赖，最后 pip freeze 来导出依赖列表到一个 requirements.txt 文件里。但是这个 txt 文件非常令人困惑。
不像 NodeJS 那么方便，想要升、降级某个依赖版本，无法自动同步到 txt 文件里。 平铺式地列出了所有一级、二级依赖包（即依赖包的依赖包）。因为 Python 某些依赖又基于系统上安装的 C 库版本，这就导致不同系统环境上执行 pip install -r requirements.txt 得到的效果并不一致，经常报错。 打包部署问题 Python 一般使用 wheel 打包二进制，它只解决打包问题，环境依赖是靠 pip 和 setuptools 完成，所以使用 wheel 你仍然要操心环境隔离和依赖管理问题。</description></item><item><title>《Python源码剖析》第三部分——Python虚拟机进阶</title><link>https://sund.site/posts/python-3/</link><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/python-3/</guid><description>Python 环境初始化 进程启动后创建 PyInterpreterObject，PyInterpreterObject 里面维护了全局 module 映射表interp-&amp;gt;modules，该表默认初始化为buildin模块，
Python 的 import 机制 Python 虚拟机在执行“import A”时，会为 package A 创建一个 module 对象，同时会在该 module 维护的 dict 中添加两个表示元信息的属性：name和path。而 Python 虚拟机从 A/init.py 中执行“import mod1”时，也会为 mod1 创建一个 module 对象，同时也会设置name属性，但是这时就不设置path属性了。
package 是由 module 聚合而成。更清楚的表述是：module 属于一个 package。我们不能说，module1 属于 module2。我们前面已经看到，module 的路径实际上是一种树状结构，从图 14-11 中可以看到，在这个树状结构中，module 的父节点只能是 package，而不可能是另一个 module。
GIL Python 虚拟机使用一个全局解释器锁（Global Interpreter Lock，GIL）来互斥线程对 python 虚拟机的使用。
注意这里 GIL 是解释器一级的互斥锁，也就是同一时间只能有一个线程占用 python 解释器。所以GIL 是用来让操作系统中分配的多个线程互斥的使用 python 解释器的，是建立在系统线程调度基础之上的一套 C API 互斥机制，是比操作系统线程资源更大粒度的锁。
Python 的线程是基于操作系统原生线程的，所以 python 的线程不是「虚拟出来的」。
那么究竟 Python 会在众多的等待线程中选择哪一个幸运儿呢？答案是，不知道。没错，对于这个问题，Python 完全没有插手，而是交给了底层的操作系统来解决。也就是说，Python 借用了底层操作系统所提供的线程调度机制来决定下一个进入 Python 解释器的线程究竟是谁。</description></item><item><title>《Python源码剖析》第二部分——Python虚拟机基础</title><link>https://sund.site/posts/python-2/</link><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/python-2/</guid><description>Python 执行环境 在编译过程中，这些包含在 Python 源代码中的静态信息都会被 Python 编译器收集起来，编译的结果中包含了字符串，常量值，字节码等在源代码中出现的一切有用的静态信息。在 Python 运行期间，这些源文件中提供的静态信息最终会被存储在一个运行时的对象中，当 Python 运行结束后，这个运行时对象中所包含的信息甚至还会被存储在一种文件中。这个对象和文件就是我们这章探索的重点：PyCodeObject 对象和 pyc 文件。
在程序运行期间，编译结果存在于内存的 PyCodeObject 对象中；而 Python 结束运行后，编译结果又被保存到了 pyc 文件中。当下一次运行相同的程序时，Python 会根据 pyc 文件中记录的编译结果直接建立内存中的 PyCodeObject 对象，而不用再次对源文件进行编译了。
从文章摘录可见，python 生成的不是编译后的文件，而是.py文件对应的静态信息——PyCodeObject，这里包括了字节码指令序列、字符串、常量。每个名字空间(类、模块、函数)都对应一个独立的 PyCodeObject。(python 连编译后的文件里存的都是个对象！)
不被 import 的 py 文件不会生成 pyc。标准库里有 py_compile 等方法也可以生成 pyc。
import 机制 导入某个模块时，先查找对应的 pyc，如果没有 pyc 就生成然后 import 这个 pyc。(所以实际导入的并不是 py 文件，而是 py 文件编译后的 PyCodeObject)。
PyFrameObject Python 程序运行时的「执行环境」。参考操作系统执行可执行文件的过程。Python 也是将函数对应的执行环境封装成栈帧的形式加载进内存。
typedef struct _frame { PyObject_VAR_HEAD struct _frame *f_back; //执行环境链上的前一个frame PyCodeObject *f_code; //PyCodeObject对象 PyObject *f_builtins; //builtin名字空间 PyObject *f_globals; //global名字空间 PyObject *f_locals; //local名字空间 PyObject **f_valuestack; //运行时栈的栈底位置 PyObject **f_stacktop; //运行时栈的栈顶位置 …… int f_lasti; //上一条字节码指令在f_code中的偏移位置 int f_lineno; //当前字节码对应的源代码行 …… //动态内存，维护（局部变量+cell对象集合+free对象集合+运行时栈）所需要的空间 PyObject *f_localsplus[1]; } PyFrameObject; Python 标准库的sys.</description></item><item><title>《Python源码剖析》第一部分——Python对象基础</title><link>https://sund.site/posts/python/</link><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid>https://sund.site/posts/python/</guid><description>Python 的对象初始化 在 Python 中，对象就是为 C 中的结构体在堆上申请的一块内存，一般来说，对象是不能被静态初始化的，并且也不能在栈空间上生存。唯一的例外就是类型对象，Python 中所有的内建的类型对象（如整数类型对象，字符串类型对象）都是被静态初始化的。
python 的对象不像 C 是分配在栈、堆、data segment 等位置，而是全部分配在堆上！只有 python 内置类型在初始化时候才是被 C 语言层静态初始化。
PyObject 内部就两样：引用计数器、类型对象指针。
类型对象的定义：
typedef struct _typeobject { PyObject_VAR_HEAD char *tp_name; /* For printing, in format &amp;#34;&amp;lt;module&amp;gt;.&amp;lt;name&amp;gt;&amp;#34; */ int tp_basicsize, tp_itemsize; /* For allocation */ /* Methods to implement standard operations */ destructor tp_dealloc; printfunc tp_print; …… /* More standard operations (here for binary compatibility) */ hashfunc tp_hash; ternaryfunc tp_call; …… } PyTypeObject; PyObject_VAR_HEAD是可变类型的头信息，其中除了PyObject_HEAD的内容外，额外添加了一个代表该对象元素数量的整型。从上边代码可见，python 的类型也是一个可变对象。</description></item><item><title>Python2 中字符类型的一些坑</title><link>https://sund.site/posts/py-str/</link><pubDate>Wed, 11 Jan 2017 11:09:00 +0000</pubDate><guid>https://sund.site/posts/py-str/</guid><description>问题 有一道面试题是这样的：
a = u&amp;#39;China&amp;#39; b = &amp;#39;China&amp;#39; c = u&amp;#39;中国&amp;#39; d = &amp;#39;中国&amp;#39; # 1 print &amp;#39;%s %s&amp;#39; % (a, b) # 2 print &amp;#39;%s&amp;#39; % c # 3 print &amp;#39;%s&amp;#39; % d # 4 print &amp;#39;%s %s&amp;#39; % (c, d) 判断打印后的效果。
先说正确答案，只有最后一行会报错。
分析 在 Python2 里，默认的字符类型是str，这个str和 Python3 的str完全不同，Python2 的str类型是 8 位的 ascii 序列。Python2 在处理str类型转换时遵循这样的规则：如果被处理的str型变量值小于 7 位，就可以和unicode类型混用。可以做+连接，格式化等操作，同 unicode 享受同样的待遇。
Python2 在格式化字符时，会把str格式化为str，如果字符串里混入了unicode，就会把其他字符都转化为unicode。所以这道题里 1 处的 a，b 两个值混合后的字符就是一个 unicode 字符串，c 和 d 单独格式化后仍保留了自己的格式。但是 Python2 在格式化代码位置 4 时，发现 c 是 unicode 而 d 不是，就会尝试按照上面的混用规则，格式化 d 为 unicode 类型，但是 d 的值'中国'显然是一个大于 7 位的str，因此 Python2 抛出 UnicodeDecodeError。</description></item><item><title>Python yield关键字的底层实现</title><link>https://sund.site/posts/py-yield/</link><pubDate>Wed, 28 Dec 2016 18:00:00 +0000</pubDate><guid>https://sund.site/posts/py-yield/</guid><description>这几天面试被问到类似的问题，顺便看了看 Python 的源码，参考网上的教程，总结一下 yield 关键字在 C 层面是如何实现的。
举个栗子 我们先看一个 python 生成器函数的例子：
from dis import dis def func(): i = 4 yield i print i dis(func) a =func() a.next() a.next() 使用 python 的库 dis 可以直接查看 python 虚拟机运行的字节码。dis(func)的打印如下：
6 0 LOAD_CONST 1 (4) 3 STORE_FAST 0 (i) 7 6 LOAD_FAST 0 (i) 9 YIELD_VALUE 10 POP_TOP 8 11 LOAD_FAST 0 (i) 14 PRINT_ITEM 15 PRINT_NEWLINE 16 LOAD_CONST 0 (None) 19 RETURN_VALUE 我们猜测其中第二列(代表字节码偏移量)为 9 的指令YIELD_VALUE就是 yield 关键字的执行代码，进入 Python2.</description></item><item><title>Python 巧妙地将rpc接口封装成pythonic的链式调用</title><link>https://sund.site/posts/py-pythonic/</link><pubDate>Tue, 25 Oct 2016 15:40:43 +0000</pubDate><guid>https://sund.site/posts/py-pythonic/</guid><description>这是一个外国人实现的 Zabbix(一个开源监控工具)的 Python Client——pyzabbix 里的代码片段。
RPC 调用 Rpc 调用的流程是向 rpc 服务端指定的 uri(如http://www.abc.com/jsonrpc.php) 发送 json(或其他双方约定格式)数据包，数据包里有 rpc 版本信息、方法名、参数等。下面Zabbix类里的do_request方法就完成了将方法名和方法参数打包 json 后发送请求的过程。
class Zabbix(object): # ... skip other class methods def do_request(self, method, params=None): request_json = { &amp;#39;jsonrpc&amp;#39;: &amp;#39;2.0&amp;#39;, &amp;#39;method&amp;#39;: method, &amp;#39;params&amp;#39;: params or {}, &amp;#39;id&amp;#39;: self.id, } response = self.session.post( self.url, data=json.dumps(request_json), timeout=self.timeout ) 技巧 但是为了方便，我们在 python 里一般使用zabbixclient.host.get(args)这样的链式调用，而不用zabbixclient('host.get', args)这样的调用方式。pyzabbix 的作者巧妙的实现了这样的转换。
class Zabbix(object): # ... skip other class methods def do_request(self, method, params=None): request_json = { &amp;#39;jsonrpc&amp;#39;: &amp;#39;2.</description></item><item><title>Python Fabric库无法启动后台进程的问题和解决办法</title><link>https://sund.site/posts/py-fabric/</link><pubDate>Wed, 19 Oct 2016 16:25:51 +0000</pubDate><guid>https://sund.site/posts/py-fabric/</guid><description>问题和处理方法 Python 的 Fabric 库能够方便的远程操作 Linux 主机执行命令或传输文件。其实现方式就是底层实现 ssh 协议，例如执行下面代码的 run 方法，在目标主机上启动一个 zabbix 后台服务：
from fabric import api from fabric.tasks import Task class Zabbix(Task): def run(self, kwargs): with api.settings(host_string=&amp;#39;192.168.1.2&amp;#39;, user=&amp;#39;root&amp;#39;, password=&amp;#39;123456&amp;#39;): api.run(&amp;#39;service zabbix_agentd start&amp;#39;) 但是这样操作后虽然 Fabric 的 output 返回结果打印是启动成功，但是 ssh 登录目标主机，却不见 zabbix_agentd 进程，这说明没有真正启动起来。
我查询了 Fabric 文档，发现需要在 api.run 里添加参数pty=False。
api.run(&amp;#39;service zabbix_agentd start&amp;#39;， pty=False) 这样就成功启动了后台进程。
原因 什么是 pty？ pty 是 pseudo-tty，众所周知 tty 是 Linux 支持输入与输出的终端设备，在 shell 下执行ps可以查看每个进程对应的 tty 设备号，如ttys0001。
pty 是为了解决远程连接时一方不希望对方直接 ssh 连接到主机上而诞生的「虚拟设备」，即伪 tty，其原理是在远程主机和本地之间同时启动 pty 端口连接终端，可以类比进程间的通道，pty 两端同时执行输入输出操作，如同本地直接连接到远程主机。但是一旦断开本地与远程主机的连接，pty 就会结束所有刚才的进程。</description></item><item><title>Python defaultdict结构作计数器的用法</title><link>https://sund.site/posts/py-defaultdict/</link><pubDate>Tue, 11 Oct 2016 15:00:16 +0000</pubDate><guid>https://sund.site/posts/py-defaultdict/</guid><description>在开发中经常需要用到计数器，当函数 foo 调用另一个函数 bar 时，为了确认调用 bar 之后处理的结果正确性，经常需要使用计数器来统计 bar 函数里处理成功了多少次。例如：
def foo(): success_num = bar() print success_num def bar(): n = 0 # 假设这个任务要迭代100次. count = 100 try: for i in count: # Do something. n += 1 except: pass finally: return n 但是，这里需要定义多个计数器变量来保存计数。每多一个 bar 函数就要多定义两次计数器。有没有类似 C 语言指针一样的方法，可以在 foo 中定义后直接传给 bar，在 bar 里修改值呢。
众所周知，Python 的参数传值实际传的是变量的拷贝，但是对于像字典、列表等非基本数据结构，实际传给参数的是这个数据结构的指针地址，修改指针地址指向的实际值就可以在函数内外实现传递数据的效果了。那么利用这个特性，可以结合 python 标准库 collections 里的 defaultdict 结构来实现一个更方便的计数器：
from collections import defaultdict def foo(): result = defaultdict(int) bar(result) print result def bar(result): count = 100 for i in count: try: # Do something.</description></item></channel></rss>