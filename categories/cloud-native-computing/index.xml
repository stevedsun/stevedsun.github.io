<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloud Native Computing on 電波障害</title><link>https://sund.site/categories/cloud-native-computing/</link><description>Recent content in Cloud Native Computing on 電波障害</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 15 Apr 2024 16:44:40 +0800</lastBuildDate><atom:link href="https://sund.site/categories/cloud-native-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>审计追踪的设计</title><link>https://sund.site/posts/2024/audit-system-design/</link><pubDate>Mon, 15 Apr 2024 16:44:40 +0800</pubDate><guid>https://sund.site/posts/2024/audit-system-design/</guid><description>什么是审计追踪（Audit Trail）服务？ 审计轨迹（Audit trail、Audit log），也译作审计追踪、审计跟踪、审计日志、文件日志或轨迹纪录等名称，是一种作为信息系统审计手段的与安全相关的时间顺序记录、记录集和/或目的地和记录来源，它们提供了在任何时候影响特定操作，程序的活动顺序的文件证据或事件。 审计记录通常来自一些活动，例如：金融交易、科学研究和医疗保健数据交易，或个人、系统、账号以及其他实体的通信等活动。 透过对系统上的活动作时间顺序的纪录，从而监察系统是否存在违规的活动，协助审核人员快速的找出相关的交易资料。 ——维基百科
审计追踪服务应该具备哪些能力？ 日志内容不可篡改。 日志链结构完整：不可任意添加或删除单独的日志条目。 兼容性：发送日志的客户端应该避免侵入式设计。 系统的加密服务应该尽早初始化，以减少未受保护的日志。 服务重启/关闭不应导致审核日志不一致。如果服务因紧急情况而关闭，审计日志应该是可验证的。 密钥安全性：加密密钥（用于计算完整性检查）应存储在专用密钥存储中，并在内存中驻留最短的时间。 性能：能够在几秒钟内验证受保护日志。 日志轮换友好性：审核日志应与分布式系统典型的日志轮换策略兼容。 可观测性：日志易于被解析（machine-readable）、人类可读（human-readable）。兼容主流日志处理程序的格式，维度设计便于日后做过滤筛选。 审计追踪涉及的行业标准 常见的工业标准有 IEC62443、NIST SP 800-92。
工业标准 章节 安全级别 IEC 62443-4-2:2019 CR2.8 SL-C 1 IEC 62443-4-2:2019 CR6.1 SL-C 1 IEC 62443-4-2:2019 CR6.2 SL_C 2 IEC 62443-4-2:2019 CR1.13 SL_C 1 IEC 62443-4-2:2019 CR2.9 SL_C 1 IEC 62443-4-2:2019 CR2.10 SL_C 1 IEC 62443-4-2:2019 CR3.7 SL_C 1 IEC 62443-4-2:2019 CR3.9 SL_C 2 常见问题及应对措施 日志格式（协议） 对于本地运行的软件，通常 Syslog 具有更好的系统兼容性。对于使用 ELK 采集日志的项目更适合用 CEF，其他情况建议使用 自定义的 JSON。</description></item><item><title>Kong网关极简入门</title><link>https://sund.site/posts/2023/kong-gateway/</link><pubDate>Fri, 23 Jun 2023 10:36:36 +0800</pubDate><guid>https://sund.site/posts/2023/kong-gateway/</guid><description>基本概念 Kong Gateway is a Lua application running in Nginx. Kong Gateway is distributed along with OpenResty, which is a bundle of modules that extend the lua-nginx-module.
Kong 是一个基于 Nginx 上运行的 Lua 程序。它改善了 Nginx 基于静态配置的缺点，可以动态添加插件和热部署。
Kong 的基础模块 Service是后端服务的抽象。
Routes是 client 到后端服务的路由规则的抽象。如，为不同的 client 设置不同的认证规则。
Kong 的 routes 有两种模式 traditional_compat 和 expressions 。
traditional_compat ：旧的基于通配符等匹配优先级的模式。 expressions ：新的基于表达式的匹配模式。 Upstreams是一个运维对象，在 Services 和真正的后台 API 服务之间，用来负载均衡。
Plugins是用 lua 或 go 编写的插件，分为 Kong 官方提供的插件和第三方插件。
Kong 的工作原理 Kong 支持三类协议：HTTP/HTTPS，TCL/TLS 和 GRPC/GRPCS。每种协议由不同的参数组成：</description></item><item><title>分布式缓存系统的设计</title><link>https://sund.site/posts/2021/distributed-cache/</link><pubDate>Thu, 18 Mar 2021 15:32:57 +0800</pubDate><guid>https://sund.site/posts/2021/distributed-cache/</guid><description>很久不写技术文章了。这是一篇关于 Redis 构建分布式缓存系统的总结，结合之前项目上的使用场景，做一个系统性的梳理。
下面就以我做过的商品预约平台项目作为引子，引出分布式缓存设计的一些要点。
该商品预约平台的背景如下：
该系统由多个微服务组成 预约的过程：用户可以选择指定门店，指定日期到店提领商品，如果对应门店和日期没有库存，则不能预约 因为“预约”的是未来时刻的库存，所以门店的未来某个时间剩余库存是通过一系列公式计算得出的。这个公式比较复杂，考虑到了用户指定的日期是否在配货周期内等因素，这里省略掉细节 每年节日高峰时期，用户会集中预约商品，导致服务压力骤增。又因为未来日期的库存需要动态计算的特点（比如 A 预约了 1 月 1 日的最后一件商品，B 就会无法在该日预约），不同用户的预约操作会互相影响，严重时导致数据库死锁、数据不一致等问题 基于以上背景，这个预约系统的设计必须将性能作为主要优化目标，而缓存作为性能优化的不二选择，就承担了重要职责。
识别热点数据 并不是所有数据都有必要被缓存，往往缓存的数据具有以下几个特点：
读写比很高。如果写操作比读操作还多，缓存系统频繁更新会大大降低可用性 是热点数据。因为内存的价格昂贵，所以按照 2-8 原则，20%热点数据才值得被缓存 能够容忍短时间的不一致 结合项目需要，排除掉一些不适合缓存的数据：
对于那些只读的、配置相关的数据，只需要做进程缓存（使用 Guava Cache），在服务启动时加载数据到内存就可以了 尽量用 CDN 和 Nginx 静态缓存来解决大部分不常更新的资源 对于该预约项目，用户最频繁查询的数据是不同门店在不同日期下的库存数量。这类数据是缓存设计的重点照顾对象：
用户选择了指定城市、指定门店后，系统会返回最近 30 天的库存信息，用户只可能修改其中一条信息。所以读写比很高 库存信息是预约订单流程的必备步骤，而且是跨服务调用（预约服务 -&amp;gt; 库存服务）的数据，所以涉及到大量网络请求、数据库查询。 指定性能优化的指标 在即将完成业务系统开发时，我们就根据 Google SRE Books 提到的四个黄金指标，制定了监控系统性能的四个维度：
请求率 错误数，非 200 返回结果数量 响应时间 资源利用率（CPU、内存） 我们使用 Prometheus + Grafana 的组合实现监控可视化，这样每次测试人员进行压力测试时，都可以通过这些指标对系统进行调整。缓存影响最大的指标是请求率（一般用 TPS 或者 QPS）和响应时间。所以在设计缓存系统时，要不断参照这两个指标进行优化。
缓存的设计的实践 分级缓存 为了不让某一接口或者微服务的缓存失效导致其他接口或服务的并发量暴增，就要针对不同来源（数据库的表、接口等）的数据做分级缓存。比如用户在一次查询中涉及到“附近可预约门店”的查询、“活动期间不同日期剩余库存”的查询、“已预约数量“的查询，这三种查询逐层依赖后边的查询结果。
假设如果只针对库存数量做缓存，一旦这部分缓存失效，那么“附近可预约门店”的查询就会直接访问数据库查询全部门店的剩余库存来确定哪个门店可以预约。这样就导致查询库存的接口并发量骤增。所以分级缓存一定程度上缓解了缓存雪崩的问题。
自动化测试 API 参数合法性 我们的 QA 通常会写自动化脚本对后端 API 做定期的扫描，检查哪些接口的数据输入、输出有不合法的类型或是数值范围。除了巩固系统的健壮性，还能帮助缓存系统抵御缓存穿透的风险。</description></item></channel></rss>